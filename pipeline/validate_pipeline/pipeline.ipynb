{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APC/AVL and OCRA files to merge\n",
    "filepath = 'C:/Users/mstark/Desktop/DATA591/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winter data\n",
    "orca_file = filepath + 'orcadata_winter.csv'\n",
    "avl_file = filepath + 'apcdata_winter.csv'\n",
    "days_to_keep = [f'2019-01-{day:02d}' for day in range(7, 32)] +  \\\n",
    "               [f'2019-02-{day:02d}' for day in range(1, 3)] +  \\\n",
    "               [f'2019-02-{day:02d}' for day in range(13, 29)] + \\\n",
    "               [f'2019-03-{day:02d}' for day in range(1, 4)]\n",
    "            \n",
    "# summer data\n",
    "# orca_file = filepath + 'orcadata_summer.csv'\n",
    "# avl_file = filepath + 'apcdata_summer.csv'\n",
    "# days_to_keep = [f'2019-07-{day:02d}' for day in range(1, 32)]  + \\\n",
    "#                [f'2019-08-{day:02d}' for day in range(1, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mstark\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (26,36,37,40,41,46,47,48,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Features: (27878358, 61)\n",
      "Columns: ['txn_id', 'trip_group_id', 'prev_leg_txn_id', 'card_serial_number', 'institution_id', 'institution_name', 'business_date', 'txn_dtm_pacific', 'txn_type_id', 'txn_subtype_id', 'txn_type_descr', 'upgrade_indicator', 'product_id', 'product_descr', 'txn_passenger_type_id', 'txn_passenger_type_descr', 'passenger_count', 'ceffv', 'service_agency_id', 'service_agency_name', 'source_agency_id', 'source_agency_name', 'transit_operator_abbrev', 'mode_id', 'mode_abbrev', 'mode_descr', 'route_number', 'direction_id', 'direction_descr', 'agency_trip_id', 'device_id', 'device_type', 'device_place_name', 'device_place_id', 'device_location_id', 'device_location_code', 'device_location_abbrev', 'device_location_descr', 'origin_location_id', 'origin_location_code', 'origin_location_abbrev', 'origin_location_descr', 'destination_location_id', 'destination_location_code', 'destination_location_abbrev', 'destination_location_descr', 'device_id_filt', 'stop_id', 'stop_time', 'stop_lat', 'stop_lon', 'stop_error', 'viaserviceareaid', 'viaserviceareaname', 'trip_id', 'last_mode_id', 'last_route_number', 'last_stop_id', 'last_stop_time', 'last_stop_lat', 'last_stop_lon']\n"
     ]
    }
   ],
   "source": [
    "# read in raw ORCA transactions\n",
    "orca_data = pd.read_csv(orca_file)\n",
    "print('Rows, Features:', orca_data.shape)\n",
    "print('Columns:', list(orca_data.columns))\n",
    "o_0 = orca_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>trip_group_id</th>\n",
       "      <th>prev_leg_txn_id</th>\n",
       "      <th>card_serial_number</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>institution_name</th>\n",
       "      <th>business_date</th>\n",
       "      <th>txn_dtm_pacific</th>\n",
       "      <th>txn_type_id</th>\n",
       "      <th>txn_subtype_id</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_error</th>\n",
       "      <th>viaserviceareaid</th>\n",
       "      <th>viaserviceareaname</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>last_mode_id</th>\n",
       "      <th>last_route_number</th>\n",
       "      <th>last_stop_id</th>\n",
       "      <th>last_stop_time</th>\n",
       "      <th>last_stop_lat</th>\n",
       "      <th>last_stop_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [txn_id, trip_group_id, prev_leg_txn_id, card_serial_number, institution_id, institution_name, business_date, txn_dtm_pacific, txn_type_id, txn_subtype_id, txn_type_descr, upgrade_indicator, product_id, product_descr, txn_passenger_type_id, txn_passenger_type_descr, passenger_count, ceffv, service_agency_id, service_agency_name, source_agency_id, source_agency_name, transit_operator_abbrev, mode_id, mode_abbrev, mode_descr, route_number, direction_id, direction_descr, agency_trip_id, device_id, device_type, device_place_name, device_place_id, device_location_id, device_location_code, device_location_abbrev, device_location_descr, origin_location_id, origin_location_code, origin_location_abbrev, origin_location_descr, destination_location_id, destination_location_code, destination_location_abbrev, destination_location_descr, device_id_filt, stop_id, stop_time, stop_lat, stop_lon, stop_error, viaserviceareaid, viaserviceareaname, trip_id, last_mode_id, last_route_number, last_stop_id, last_stop_time, last_stop_lat, last_stop_lon]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print any duplicate in OCRA data\n",
    "ocra_dups = orca_data[orca_data.duplicated()]\n",
    "print('Duplicate records:', ocra_dups.shape[0])\n",
    "ocra_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           245\n",
       "1           510\n",
       "2            40\n",
       "3             3\n",
       "4           676\n",
       "5           522\n",
       "6           542\n",
       "7           560\n",
       "8            33\n",
       "9           542\n",
       "10            3\n",
       "11          542\n",
       "12          672\n",
       "13          271\n",
       "14          167\n",
       "15          271\n",
       "16          672\n",
       "17          550\n",
       "18            4\n",
       "19          550\n",
       "20          532\n",
       "21          532\n",
       "22          130\n",
       "23          512\n",
       "24           33\n",
       "25          554\n",
       "26           70\n",
       "27          542\n",
       "28           24\n",
       "29            3\n",
       "           ... \n",
       "27878328    109\n",
       "27878329    421\n",
       "27878330      2\n",
       "27878331     70\n",
       "27878332    240\n",
       "27878333     40\n",
       "27878334     11\n",
       "27878335     70\n",
       "27878336    522\n",
       "27878337     45\n",
       "27878338      2\n",
       "27878339    594\n",
       "27878340    512\n",
       "27878341    512\n",
       "27878342    532\n",
       "27878343    412\n",
       "27878344     29\n",
       "27878345     11\n",
       "27878346    550\n",
       "27878347     32\n",
       "27878348    512\n",
       "27878349     33\n",
       "27878350     36\n",
       "27878351    550\n",
       "27878352    550\n",
       "27878353    554\n",
       "27878354    240\n",
       "27878355      3\n",
       "27878356     70\n",
       "27878357    855\n",
       "Name: route_number, Length: 27878358, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca_data['route_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce columns\n",
    "orca_cols_to_keep = ['institution_name', 'business_date', 'txn_dtm_pacific', 'txn_passenger_type_descr',\n",
    "                     'passenger_count', 'service_agency_id', 'mode_id', 'route_number', 'direction_descr',\n",
    "                     'direction_id', 'stop_id', 'trip_id']\n",
    "orca_data = orca_data[orca_cols_to_keep]\n",
    "o_1 = orca_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep days, service_agency_id = 4, mode_id in [128, 250], and route_numbers [<600, between 671 and 676]\n",
    "orca_data['route_number'] = pd.to_numeric(orca_data['route_number'], errors='coerce')\n",
    "orca_data = orca_data[(orca_data['business_date'].isin(days_to_keep)) \n",
    "                      & (orca_data['service_agency_id'] == 4)\n",
    "                      & (orca_data['mode_id'].isin([128, 250]))\n",
    "                      & ((orca_data['route_number'] < 600) \n",
    "                         | ((orca_data['route_number'] >= 671) & (orca_data['route_number'] <= 676)))]\n",
    "o_2 = orca_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n",
    "# orca_data['is_rapidride'] = [1 if x > 600 else 0 for x in orca_data['route_number']]\n",
    "# orca_data['day_of_week'] = pd.to_datetime(orca_data['business_date']).dt.dayofweek\n",
    "# orca_data['biz_txn_diff'] = (pd.to_datetime(orca_data['business_date']).dt.date \n",
    "#                              - pd.to_datetime(orca_data['txn_dtm_pacific']).dt.date)/np.timedelta64(1, 'D')\n",
    "\n",
    "orca_data['orca_total'] = orca_data['passenger_count']\n",
    "orca_data['orca_adult'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Adult', 0)\n",
    "orca_data['orca_disabled'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Disabled', 0)\n",
    "orca_data['orca_senior'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Senior', 0)\n",
    "orca_data['orca_youth'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Youth', 0)\n",
    "orca_data['orca_lowincome'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Low Income', 0)\n",
    "orca_data['orca_uw'] = orca_data['passenger_count'].where(orca_data['institution_name'] == 'University of Washington', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preserved 9788082 rows of 27878358 from OCRA transtions. 35.10996594562707 %\n"
     ]
    }
   ],
   "source": [
    "# cleaned ORCA results\n",
    "print('Preserved', o_2, 'rows of', o_0, 'from OCRA transtions.', o_2*1.0/o_0*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4792868\n"
     ]
    }
   ],
   "source": [
    "# aggregate ORCA over day, trip, stop, route\n",
    "orca_agg_groupby = ['business_date', 'trip_id', 'stop_id', 'route_number']\n",
    "orca_agg_sumover = ['orca_total', 'orca_adult', 'orca_disabled', 'orca_senior', 'orca_youth', 'orca_lowincome', 'orca_uw']\n",
    "orca_agg = orca_data[orca_agg_groupby + orca_agg_sumover].groupby(orca_agg_groupby).sum().reset_index()\n",
    "print('Rows:', orca_agg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Features: (20535948, 32)\n"
     ]
    }
   ],
   "source": [
    "# read in AVL/APC data\n",
    "avl_data = pd.read_csv(avl_file)\n",
    "print('Rows, Features:', avl_data.shape)\n",
    "a_0 = avl_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>daycode</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>pattern_quality</th>\n",
       "      <th>blk</th>\n",
       "      <th>rte</th>\n",
       "      <th>dir</th>\n",
       "      <th>sch_st_min</th>\n",
       "      <th>opd_date</th>\n",
       "      <th>...</th>\n",
       "      <th>apc_veh</th>\n",
       "      <th>ons</th>\n",
       "      <th>offs</th>\n",
       "      <th>load</th>\n",
       "      <th>geom</th>\n",
       "      <th>sch_stop_tm.1</th>\n",
       "      <th>act_stop_tm.1</th>\n",
       "      <th>stop_datetime</th>\n",
       "      <th>gps_lat</th>\n",
       "      <th>gps_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40956049</td>\n",
       "      <td>10994010</td>\n",
       "      <td>100</td>\n",
       "      <td>99401</td>\n",
       "      <td>994</td>\n",
       "      <td>N</td>\n",
       "      <td>467.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-07 07:49:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000002D15D1C50B955EC0BD6EE4D599DD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40956861</td>\n",
       "      <td>82565531</td>\n",
       "      <td>100</td>\n",
       "      <td>99402</td>\n",
       "      <td>994</td>\n",
       "      <td>S</td>\n",
       "      <td>994.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-07 16:40:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000004C9BD4951D955EC044C3F693B8CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40421104</td>\n",
       "      <td>40989003</td>\n",
       "      <td>100</td>\n",
       "      <td>98902</td>\n",
       "      <td>989</td>\n",
       "      <td>E</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-07 16:14:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E610000074BDADDFF58A5EC05720E56F4DC8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40422735</td>\n",
       "      <td>82565529</td>\n",
       "      <td>100</td>\n",
       "      <td>98901</td>\n",
       "      <td>989</td>\n",
       "      <td>W</td>\n",
       "      <td>488.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-07 08:10:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000006968101067955EC05A1F426864DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40956859</td>\n",
       "      <td>82565528</td>\n",
       "      <td>100</td>\n",
       "      <td>98802</td>\n",
       "      <td>988</td>\n",
       "      <td>S</td>\n",
       "      <td>991.0</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-07 16:25:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000004839443162935EC0BCDDF707C8CD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  daycode   trip_id  pattern_id  pattern_quality    blk  rte dir  \\\n",
       "0           0        0  40956049    10994010              100  99401  994   N   \n",
       "1           1        0  40956861    82565531              100  99402  994   S   \n",
       "2           2        0  40421104    40989003              100  98902  989   E   \n",
       "3           3        0  40422735    82565529              100  98901  989   W   \n",
       "4           4        0  40956859    82565528              100  98802  988   S   \n",
       "\n",
       "   sch_st_min    opd_date                        ...                          \\\n",
       "0       467.0  2019-01-07                        ...                           \n",
       "1       994.0  2019-01-07                        ...                           \n",
       "2      1002.0  2019-01-07                        ...                           \n",
       "3       488.0  2019-01-07                        ...                           \n",
       "4       991.0  2019-01-07                        ...                           \n",
       "\n",
       "   apc_veh  ons  offs  load geom  sch_stop_tm.1  act_stop_tm.1  \\\n",
       "0        Y  0.0   7.0   0.0   ST            NaN            NaN   \n",
       "1        N  NaN   NaN   NaN  STE            NaN            NaN   \n",
       "2        Y  0.0   1.0   0.0  STE            NaN            NaN   \n",
       "3        Y  0.0  17.0   0.0   ST            NaN            NaN   \n",
       "4        N  NaN   NaN   NaN  STE            NaN            NaN   \n",
       "\n",
       "         stop_datetime gps_lat  \\\n",
       "0  2019-01-07 07:49:57     NaN   \n",
       "1  2019-01-07 16:40:17     NaN   \n",
       "2  2019-01-07 16:14:36     NaN   \n",
       "3  2019-01-07 08:10:10     NaN   \n",
       "4  2019-01-07 16:25:08     NaN   \n",
       "\n",
       "                                            gps_long  \n",
       "0  0101000020E61000002D15D1C50B955EC0BD6EE4D599DD...  \n",
       "1  0101000020E61000004C9BD4951D955EC044C3F693B8CC...  \n",
       "2  0101000020E610000074BDADDFF58A5EC05720E56F4DC8...  \n",
       "3  0101000020E61000006968101067955EC05A1F426864DE...  \n",
       "4  0101000020E61000004839443162935EC0BCDDF707C8CD...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avl_header = ['daycode', 'trip_id', 'pattern_id', 'pattern_quality', 'blk', 'rte', 'dir', 'sch_st_min', 'opd_date',\n",
    "              'pattern_quality_1', 'vehicle_id', 'stop_id', 'stop_seq', 'stop_name', 'sch_stop_sec', 'act_stop_arr',\n",
    "              'sch_stop_tm', 'act_stop_tm', 'dwell_sec', 'doors_open', 'door_open_sec', 'apc_veh', 'ons', 'offs',\n",
    "              'load', 'geom', 'sch_stop_tm', 'act_stop_tm', 'stop_datetime','gps_lat', 'gps_long']\n",
    "avl_data.columns = avl_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates in raw file\n",
    "avl_dups = avl_data[avl_data.duplicated()]\n",
    "a_05 = avl_dups.shape[0]\n",
    "print('Duplicate records:', avl_dups.shape[0])\n",
    "avl_dups.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate records\n",
    "avl_data = avl_data.drop_duplicates()\n",
    "a_1 = avl_data.shape[0]\n",
    "print('Validate all rows accounted for:', a_0, a_05+a_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep days, apc vehic le, and rte [<600, between 671 and 676]\n",
    "avl_data = avl_data[(avl_data['opd_date'].isin(days_to_keep))\n",
    "                   & (avl_data['apc_veh'] == 'Y')\n",
    "                   & ((avl_data['rte'].astype(int) < 600) \n",
    "                      | ((avl_data['rte'].astype(int) >= 671) & (avl_data['rte'].astype(int) <= 676)))]\n",
    "a_2 = avl_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "avl_data['day_of_week'] = pd.to_datetime(avl_data['opd_date']).dt.dayofweek\n",
    "avl_data['is_rapidride'] = [1 if x > 600 else 0 for x in avl_data['rte'].astype(int)]\n",
    "avl_data['opd_txn_diff'] = (pd.to_datetime(avl_data['opd_date']).dt.date\n",
    "                             - pd.to_datetime(avl_data['stop_datetime']).dt.date)/np.timedelta64(1, 'D')\n",
    "avl_data['ons_update'] = [x if x < 150 else None for x in avl_data['ons']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned APC results\n",
    "print('Preserved', a_2, 'row of', a_0, 'from APC transtions.', a_2*1.0/a_0*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate APC over day, trip, stop, route\n",
    "avl_agg_groupby = ['opd_date', 'trip_id', 'stop_id', 'rte', 'dir', 'is_rapidride', 'day_of_week']\n",
    "avl_agg_sumover = ['ons', 'offs', 'load', 'ons_update']\n",
    "avl_agg = avl_data[avl_agg_groupby + avl_agg_sumover].groupby(avl_agg_groupby).sum().reset_index()\n",
    "print('Rows:', avl_agg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge orca_agg and apc_agg\n",
    "merged_data = pd.merge(avl_agg, orca_agg, \n",
    "                       left_on = ['trip_id', 'stop_id', 'opd_date', 'rte'],\n",
    "                       right_on = ['trip_id', 'stop_id', 'business_date', 'route_number'],\n",
    "                       how = 'inner',\n",
    "                       suffixes = ('_apc', '_orca'))\n",
    "print('Rows, Features:', merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check merged_data is unique\n",
    "distinct_col = ['opd_date', 'trip_id', 'stop_id']\n",
    "merge_dups = merged_data[merged_data[distinct_col].duplicated()]\n",
    "print('Duplicate records:', merge_dups.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll up ons/counts to trip_id (drop stop_id)\n",
    "trip_groupby = ['opd_date', 'day_of_week', 'trip_id', 'rte', 'is_rapidride', 'dir', 'route_number']\n",
    "trip_sumover = ['ons', 'offs', 'ons_update'] + list(merged_data.columns)[-7:]\n",
    "print(trip_sumover)\n",
    "trip_agg = merged_data[trip_groupby + trip_sumover].groupby(trip_groupby).sum().reset_index()\n",
    "print('Rows, Features:', trip_agg.shape)\n",
    "trip_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot apc vs ORCA\n",
    "plt.scatter(trip_agg['ons'], trip_agg['orca_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find valid trips, where ocra <= apc and apc >= 0\n",
    "trip_agg_sub0 = trip_agg[trip_agg['orca_total'] > trip_agg['ons']]\n",
    "print('Rows where OCRA > APC for trip', trip_agg_sub0.shape[0])\n",
    "\n",
    "trip_agg_sub1 = trip_agg[(trip_agg['ons'] >= 0) & (trip_agg['orca_total'] <= trip_agg['ons'])]\n",
    "print('Rows where OCRA < APC and APC >= 0 for trip:', trip_agg_sub1.shape[0])\n",
    "\n",
    "trip_agg_sub2 = trip_agg[(trip_agg['ons_update'] >= 0) & (trip_agg['orca_total'] <= trip_agg['ons_update'])]\n",
    "print('Rows where OCRA < APC and APC >= 0 for trip (ons < 150 at every apc):', trip_agg_sub2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot valid apc vs ORCA\n",
    "plt.scatter(trip_agg_sub1['ons'], trip_agg_sub1['orca_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot valid apc vs ORCA (ons < 150 at every stop)\n",
    "plt.scatter(trip_agg_sub1['ons_update'], trip_agg_sub1['orca_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of ORCA/APC ratio for trip/day\n",
    "# trip_agg_sub1['ratio_0'] = trip_agg_sub1['orca_total']/trip_agg_sub1['ons']\n",
    "trip_agg_sub2['ratio_1'] = trip_agg_sub2['orca_total']/trip_agg_sub2['ons_update']\n",
    "print('Average ratio:', np.mean(trip_agg_sub2['ratio_1']))\n",
    "plt.hist(trip_agg_sub2['ratio_1'], bins = 100)\n",
    "plt.xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "orca_data.to_csv(filepath + 'data/ORCA_cleaned.csv')\n",
    "print(orca_data.shape)\n",
    "orca_agg.to_csv(filepath + 'data/ORCA_aggregate.csv')\n",
    "print(orca_agg.shape)\n",
    "avl_data.to_csv(filepath + 'data/APC_cleaned.csv')\n",
    "print(avl_data.shape)\n",
    "avl_agg.to_csv(filepath + 'data/APC_aggregate.csv')\n",
    "print(avl_agg.shape)\n",
    "trip_agg_sub2.to_csv(filepath + 'data/trip_rollup.csv')\n",
    "print(trip_agg_sub2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get earliest trip time\n",
    "trip_time = avl_data[['opd_date', 'trip_id', 'stop_datetime']].groupby(['opd_date', 'trip_id']).min().reset_index()\n",
    "\n",
    "def hour_rounder(interval, t):\n",
    "    if interval == .5:\n",
    "        if t.minute > 30:\n",
    "            x = t.replace(second=0, microsecond=0, minute=30, hour=t.hour).strftime('%H:%M:%S')\n",
    "        else:\n",
    "            x = t.replace(second=0, microsecond=0, minute=0, hour=t.hour).strftime('%H:%M:%S')\n",
    "    else:\n",
    "        y = t.hour\n",
    "        if t.hour % interval != 0:\n",
    "            y = t.hour - t.hour % interval\n",
    "        x = t.replace(second=0, microsecond=0, minute=0, hour=y).strftime('%H:%M:%S')\n",
    "    return x\n",
    "\n",
    "trip_time['halfhr'] = [hour_rounder(.5, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['1hr'] = [hour_rounder(1, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['2hr'] = [hour_rounder(2, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['4hr'] = [hour_rounder(4, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['6hr'] = [hour_rounder(6, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make training sets\n",
    "time_intervals = ['halfhr', '1hr', '2hr', '4hr', '6hr']\n",
    "\n",
    "for val in time_intervals:\n",
    "    set_data = trip_agg_sub2.drop(['route_number', 'ratio_1'], axis = 1)\n",
    "    set_data = pd.merge(set_data , trip_time[['opd_date', 'trip_id', val]], \n",
    "                        left_on=['trip_id', 'opd_date'],\n",
    "                        right_on=['trip_id', 'opd_date'],\n",
    "                        how='inner',\n",
    "                        suffixes=('_data', '_time'))\n",
    "    set_data['ons'] = set_data['ons_update']\n",
    "    set_data = set_data.drop(['trip_id', 'ons_update'], axis = 1).groupby(['opd_date', 'rte', 'dir', 'day_of_week', 'is_rapidride', val]).sum().reset_index()\n",
    "    \n",
    "    cols = list(set_data.columns)\n",
    "    cols.remove('ons')\n",
    "    X = set_data[cols]\n",
    "    y = set_data['ons']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "    \n",
    "    print(np.sum(y))\n",
    "#     print(set_data.head(5))\n",
    "    print(val + \"(train, test, val):\", X_train.shape[0], X_test.shape[0], X_val.shape[0])\n",
    "    X_train.to_csv(filepath + '/data/' + val + '/X_train.csv')\n",
    "    X_test.to_csv(filepath + '/data/' + val + '/X_test.csv')\n",
    "    X_val.to_csv(filepath + '/data/' + val + '/X_val.csv')\n",
    "    y_train.to_csv(filepath + '/data/' + val + '/y_train.csv')\n",
    "    y_test.to_csv(filepath + '/data/' + val + '/y_test.csv')\n",
    "    y_val.to_csv(filepath + '/data/' + val + '/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare previous pipeline results with this\n",
    "compare = pd.read_csv(filepath + '49_merged_at_stop_level.tsv.gz', sep='\\t')\n",
    "compare_dups = compare[['opd_date', 'trip_id', 'stop_id', 'ons', 'orca_total']][compare[['opd_date', 'trip_id', 'stop_id']].duplicated()]\n",
    "print(compare_dups.shape)\n",
    "compare_dups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rte 49 from prior pipeline\n",
    "compare[(compare['trip_id'] == 40684352) \n",
    "        & (compare['opd_date'] == '2019-03-01') \n",
    "        & (compare['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rte 49 from current pipeline\n",
    "merged_data[(merged_data['trip_id'] == 40684352) \n",
    "            & (merged_data['opd_date'] == '2019-03-01') \n",
    "            & (merged_data['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rte 49 from raw ORCA\n",
    "orca_data[(orca_data['business_date'] == '2019-03-01') \n",
    "          & (orca_data['trip_id'] == 40684352)\n",
    "          & (orca_data['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rte 49 from raw APC\n",
    "avl_data[(avl_data['opd_date'] == '2019-03-01')\n",
    "         & (avl_data['trip_id'] == 40684352)\n",
    "         & (avl_data['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total rte 49 APC and ORCA for 3/1/19 & 3/2/19 from prior pipeline\n",
    "compare[['ons', 'orca_total']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total rte 49 APC and ORCA for 3/1/19 & 3/2/19 from this pipeline\n",
    "trip_agg_sub2[['ons', 'orca_total']][((trip_agg_sub2['opd_date'] == '2019-03-01') \n",
    "                                      | (trip_agg_sub2['opd_date'] == '2019-03-02')) \n",
    "                                     &(trip_agg_sub2['rte'] ==49)].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
