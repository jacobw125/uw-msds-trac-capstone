{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APC/AVL and OCRA files to merge\n",
    "filepath = 'C:/Users/mstark/Desktop/DATA591/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winter data\n",
    "orca_file = filepath + 'orcadata_winter.csv'\n",
    "avl_file = filepath + 'apcdata_winter.csv'\n",
    "days_to_keep = [f'2019-01-{day:02d}' for day in range(7, 32)] +  \\\n",
    "               [f'2019-02-{day:02d}' for day in range(1, 3)] +  \\\n",
    "               [f'2019-02-{day:02d}' for day in range(13, 29)] + \\\n",
    "               [f'2019-03-{day:02d}' for day in range(1, 4)]\n",
    "            \n",
    "# summer data\n",
    "# orca_file = filepath + 'orcadata_summer.csv'\n",
    "# avl_file = filepath + 'apcdata_summer.csv'\n",
    "# days_to_keep = [f'2019-07-{day:02d}' for day in range(1, 32)]  + \\\n",
    "#                [f'2019-08-{day:02d}' for day in range(1, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in raw ORCA transactions\n",
    "orca_data = pd.read_csv(orca_file)\n",
    "print('Rows, Features:', orca_data.shape)\n",
    "print('Columns:', list(orca_data.columns))\n",
    "o_0 = orca_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print any duplicate in OCRA data\n",
    "ocra_dups = orca_data[orca_data.duplicated()]\n",
    "print('Duplicate records:', ocra_dups.shape[0])\n",
    "ocra_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_data['route_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce columns\n",
    "orca_cols_to_keep = ['institution_name', 'business_date', 'txn_dtm_pacific', 'txn_passenger_type_descr',\n",
    "                     'passenger_count', 'service_agency_id', 'mode_id', 'route_number', 'direction_descr',\n",
    "                     'direction_id', 'stop_id', 'trip_id']\n",
    "orca_data = orca_data[orca_cols_to_keep]\n",
    "o_1 = orca_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep days, service_agency_id = 4, mode_id in [128, 250], and route_numbers [<600, between 671 and 676]\n",
    "orca_data['route_number'] = pd.to_numeric(orca_data['route_number'], errors='coerce')\n",
    "orca_data = orca_data[(orca_data['business_date'].isin(days_to_keep)) \n",
    "                      & (orca_data['service_agency_id'] == 4)\n",
    "                      & (orca_data['mode_id'].isin([128, 250]))\n",
    "                      & ((orca_data['route_number'] < 600) \n",
    "                         | ((orca_data['route_number'] >= 671) & (orca_data['route_number'] <= 676)))]\n",
    "o_2 = orca_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n",
    "# orca_data['is_rapidride'] = [1 if x > 600 else 0 for x in orca_data['route_number']]\n",
    "# orca_data['day_of_week'] = pd.to_datetime(orca_data['business_date']).dt.dayofweek\n",
    "# orca_data['biz_txn_diff'] = (pd.to_datetime(orca_data['business_date']).dt.date \n",
    "#                              - pd.to_datetime(orca_data['txn_dtm_pacific']).dt.date)/np.timedelta64(1, 'D')\n",
    "\n",
    "orca_data['orca_total'] = orca_data['passenger_count']\n",
    "orca_data['orca_adult'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Adult', 0)\n",
    "orca_data['orca_disabled'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Disabled', 0)\n",
    "orca_data['orca_senior'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Senior', 0)\n",
    "orca_data['orca_youth'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Youth', 0)\n",
    "orca_data['orca_lowincome'] = orca_data['passenger_count'].where(orca_data['txn_passenger_type_descr'] == 'Low Income', 0)\n",
    "orca_data['orca_uw'] = orca_data['passenger_count'].where(orca_data['institution_name'] == 'University of Washington', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned ORCA results\n",
    "print('Preserved', o_2, 'rows of', o_0, 'from OCRA transtions.', o_2*1.0/o_0*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate ORCA over day, trip, stop, route\n",
    "orca_agg_groupby = ['business_date', 'trip_id', 'stop_id', 'route_number']\n",
    "orca_agg_sumover = ['orca_total', 'orca_adult', 'orca_disabled', 'orca_senior', 'orca_youth', 'orca_lowincome', 'orca_uw']\n",
    "orca_agg = orca_data[orca_agg_groupby + orca_agg_sumover].groupby(orca_agg_groupby).sum().reset_index()\n",
    "print('Rows:', orca_agg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in AVL/APC data\n",
    "avl_data = pd.read_csv(avl_file, header = None)\n",
    "print('Rows, Features:', avl_data.shape)\n",
    "a_0 = avl_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avl_header = ['daycode', 'trip_id', 'pattern_id', 'pattern_quality', 'blk', 'rte', 'dir', 'sch_st_min', 'opd_date',\n",
    "              'pattern_quality_1', 'vehicle_id', 'stop_id', 'stop_seq', 'stop_name', 'sch_stop_sec', 'act_stop_arr',\n",
    "              'sch_stop_tm', 'act_stop_tm', 'dwell_sec', 'doors_open', 'door_open_sec', 'apc_veh', 'ons', 'offs',\n",
    "              'load', 'geom', 'sch_stop_tm', 'act_stop_tm', 'stop_datetime','gps_lat', 'gps_long']\n",
    "avl_data.columns = avl_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates in raw file\n",
    "avl_dups = avl_data[avl_data.duplicated()]\n",
    "a_05 = avl_dups.shape[0]\n",
    "print('Duplicate records:', avl_dups.shape[0])\n",
    "avl_dups.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate records\n",
    "avl_data = avl_data.drop_duplicates()\n",
    "a_1 = avl_data.shape[0]\n",
    "print('Validate all rows accounted for:', a_0, a_05+a_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep days, apc vehic le, and rte [<600, between 671 and 676]\n",
    "avl_data = avl_data[(avl_data['opd_date'].isin(days_to_keep))\n",
    "                   & (avl_data['apc_veh'] == 'Y')\n",
    "                   & ((avl_data['rte'].astype(int) < 600) \n",
    "                      | ((avl_data['rte'].astype(int) >= 671) & (avl_data['rte'].astype(int) <= 676)))]\n",
    "a_2 = avl_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "avl_data['day_of_week'] = pd.to_datetime(avl_data['opd_date']).dt.dayofweek\n",
    "avl_data['is_rapidride'] = [1 if x > 600 else 0 for x in avl_data['rte'].astype(int)]\n",
    "avl_data['opd_txn_diff'] = (pd.to_datetime(avl_data['opd_date']).dt.date\n",
    "                             - pd.to_datetime(avl_data['stop_datetime']).dt.date)/np.timedelta64(1, 'D')\n",
    "avl_data['ons_update'] = [x if x < 150 else None for x in avl_data['ons']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned APC results\n",
    "print('Preserved', a_2, 'row of', a_0, 'from APC transtions.', a_2*1.0/a_0*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate APC over day, trip, stop, route\n",
    "avl_agg_groupby = ['opd_date', 'trip_id', 'stop_id', 'rte', 'dir', 'is_rapidride', 'day_of_week']\n",
    "avl_agg_sumover = ['ons', 'offs', 'load', 'ons_update']\n",
    "avl_agg = avl_data[avl_agg_groupby + avl_agg_sumover].groupby(avl_agg_groupby).sum().reset_index()\n",
    "print('Rows:', avl_agg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge orca_agg and apc_agg\n",
    "merged_data = pd.merge(avl_agg, orca_agg, \n",
    "                       left_on = ['trip_id', 'stop_id', 'opd_date', 'rte'],\n",
    "                       right_on = ['trip_id', 'stop_id', 'business_date', 'route_number'],\n",
    "                       how = 'inner',\n",
    "                       suffixes = ('_apc', '_orca'))\n",
    "print('Rows, Features:', merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check merged_data is unique\n",
    "distinct_col = ['opd_date', 'trip_id', 'stop_id']\n",
    "merge_dups = merged_data[merged_data[distinct_col].duplicated()]\n",
    "print('Duplicate records:', merge_dups.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll up ons/counts to trip_id (drop stop_id)\n",
    "trip_groupby = ['opd_date', 'day_of_week', 'trip_id', 'rte', 'is_rapidride', 'dir', 'route_number']\n",
    "trip_sumover = ['ons', 'offs', 'ons_update'] + list(merged_data.columns)[-7:]\n",
    "print(trip_sumover)\n",
    "trip_agg = merged_data[trip_groupby + trip_sumover].groupby(trip_groupby).sum().reset_index()\n",
    "print('Rows, Features:', trip_agg.shape)\n",
    "trip_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot apc vs ORCA\n",
    "plt.scatter(trip_agg['ons'], trip_agg['orca_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find valid trips, where ocra <= apc and apc >= 0\n",
    "trip_agg_sub0 = trip_agg[trip_agg['orca_total'] > trip_agg['ons']]\n",
    "print('Rows where OCRA > APC for trip', trip_agg_sub0.shape[0])\n",
    "\n",
    "trip_agg_sub1 = trip_agg[(trip_agg['ons'] >= 0) & (trip_agg['orca_total'] <= trip_agg['ons'])]\n",
    "print('Rows where OCRA < APC and APC >= 0 for trip:', trip_agg_sub1.shape[0])\n",
    "\n",
    "trip_agg_sub2 = trip_agg[(trip_agg['ons_update'] >= 0) & (trip_agg['orca_total'] <= trip_agg['ons_update'])]\n",
    "print('Rows where OCRA < APC and APC >= 0 for trip (ons < 150 at every apc):', trip_agg_sub2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot valid apc vs ORCA\n",
    "plt.scatter(trip_agg_sub1['ons'], trip_agg_sub1['orca_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot valid apc vs ORCA (ons < 150 at every stop)\n",
    "plt.scatter(trip_agg_sub1['ons_update'], trip_agg_sub1['orca_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of ORCA/APC ratio for trip/day\n",
    "# trip_agg_sub1['ratio_0'] = trip_agg_sub1['orca_total']/trip_agg_sub1['ons']\n",
    "trip_agg_sub2['ratio_1'] = trip_agg_sub2['orca_total']/trip_agg_sub2['ons_update']\n",
    "print('Average ratio:', np.mean(trip_agg_sub2['ratio_1']))\n",
    "plt.hist(trip_agg_sub2['ratio_1'], bins = 100)\n",
    "plt.xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "orca_data.to_csv(filepath + 'data/ORCA_cleaned.csv')\n",
    "print(orca_data.shape)\n",
    "orca_agg.to_csv(filepath + 'data/ORCA_aggregate.csv')\n",
    "print(orca_agg.shape)\n",
    "avl_data.to_csv(filepath + 'data/APC_cleaned.csv')\n",
    "print(avl_data.shape)\n",
    "avl_agg.to_csv(filepath + 'data/APC_aggregate.csv')\n",
    "print(avl_agg.shape)\n",
    "trip_agg_sub2.to_csv(filepath + 'data/trip_rollup.csv')\n",
    "print(trip_agg_sub2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get earliest trip time\n",
    "trip_time = avl_data[['opd_date', 'trip_id', 'stop_datetime']].groupby(['opd_date', 'trip_id']).min().reset_index()\n",
    "\n",
    "def hour_rounder(interval, t):\n",
    "    if interval == .5:\n",
    "        if t.minute > 30:\n",
    "            x = t.replace(second=0, microsecond=0, minute=30, hour=t.hour).strftime('%H:%M:%S')\n",
    "        else:\n",
    "            x = t.replace(second=0, microsecond=0, minute=0, hour=t.hour).strftime('%H:%M:%S')\n",
    "    else:\n",
    "        y = t.hour\n",
    "        if t.hour % interval != 0:\n",
    "            y = t.hour - t.hour % interval\n",
    "        x = t.replace(second=0, microsecond=0, minute=0, hour=y).strftime('%H:%M:%S')\n",
    "    return x\n",
    "\n",
    "trip_time['halfhr'] = [hour_rounder(.5, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['1hr'] = [hour_rounder(1, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['2hr'] = [hour_rounder(2, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['4hr'] = [hour_rounder(4, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time['6hr'] = [hour_rounder(6, x) for x in pd.to_datetime(trip_time['stop_datetime'])]\n",
    "trip_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make training sets\n",
    "time_intervals = ['halfhr', '1hr', '2hr', '4hr', '6hr']\n",
    "\n",
    "for val in time_intervals:\n",
    "    set_data = trip_agg_sub2.drop(['route_number', 'ratio_1'], axis = 1)\n",
    "    set_data = pd.merge(set_data , trip_time[['opd_date', 'trip_id', val]], \n",
    "                        left_on=['trip_id', 'opd_date'],\n",
    "                        right_on=['trip_id', 'opd_date'],\n",
    "                        how='inner',\n",
    "                        suffixes=('_data', '_time'))\n",
    "    set_data['ons'] = set_data['ons_update']\n",
    "    set_data = set_data.drop(['trip_id', 'ons_update'], axis = 1).groupby(['opd_date', 'rte', 'dir', 'day_of_week', 'is_rapidride', val]).sum().reset_index()\n",
    "    \n",
    "    cols = list(set_data.columns)\n",
    "    cols.remove('ons')\n",
    "    X = set_data[cols]\n",
    "    y = set_data['ons']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "    \n",
    "    print(np.sum(y))\n",
    "#     print(set_data.head(5))\n",
    "    print(val + \"(train, test, val):\", X_train.shape[0], X_test.shape[0], X_val.shape[0])\n",
    "    X_train.to_csv(filepath + '/data/' + val + '/X_train.csv')\n",
    "    X_test.to_csv(filepath + '/data/' + val + '/X_test.csv')\n",
    "    X_val.to_csv(filepath + '/data/' + val + '/X_val.csv')\n",
    "    y_train.to_csv(filepath + '/data/' + val + '/y_train.csv')\n",
    "    y_test.to_csv(filepath + '/data/' + val + '/y_test.csv')\n",
    "    y_val.to_csv(filepath + '/data/' + val + '/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare previous pipeline results with this\n",
    "compare = pd.read_csv(filepath + '49_merged_at_stop_level.tsv.gz', sep='\\t')\n",
    "compare_dups = compare[['opd_date', 'trip_id', 'stop_id', 'ons', 'orca_total']][compare[['opd_date', 'trip_id', 'stop_id']].duplicated()]\n",
    "print(compare_dups.shape)\n",
    "compare_dups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rte 49 from prior pipeline\n",
    "compare[(compare['trip_id'] == 40684352) \n",
    "        & (compare['opd_date'] == '2019-03-01') \n",
    "        & (compare['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rte 49 from current pipeline\n",
    "merged_data[(merged_data['trip_id'] == 40684352) \n",
    "            & (merged_data['opd_date'] == '2019-03-01') \n",
    "            & (merged_data['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rte 49 from raw ORCA\n",
    "orca_data[(orca_data['business_date'] == '2019-03-01') \n",
    "          & (orca_data['trip_id'] == 40684352)\n",
    "          & (orca_data['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rte 49 from raw APC\n",
    "avl_data[(avl_data['opd_date'] == '2019-03-01')\n",
    "         & (avl_data['trip_id'] == 40684352)\n",
    "         & (avl_data['stop_id'] == 1180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total rte 49 APC and ORCA for 3/1/19 & 3/2/19 from prior pipeline\n",
    "compare[['ons', 'orca_total']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total rte 49 APC and ORCA for 3/1/19 & 3/2/19 from this pipeline\n",
    "trip_agg_sub2[['ons', 'orca_total']][((trip_agg_sub2['opd_date'] == '2019-03-01') \n",
    "                                      | (trip_agg_sub2['opd_date'] == '2019-03-02')) \n",
    "                                     &(trip_agg_sub2['rte'] ==49)].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
