{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bitbaseconda7b74234baf454d23886bd31545e276ad",
   "display_name": "Python 3.6.2 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n3.6.2 |Anaconda custom (64-bit)| (default, Sep 21 2017, 18:29:43) \n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
    }
   ],
   "source": [
    "from sys import version\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training dimension: (542954, 20)\nXval dimension: (67876, 20)\nopd_date\ntrip_start_hr_15\nrte\ndir\nday_of_week\nis_ns\nis_rapid\nis_weekend\norca_total\nfrac_disabled\nfrac_youth\nfrac_senior\nfrac_li\nfrac_uw\nons\nregion\nstart\nend\ntype\nsummer\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>opd_date</th>\n      <td>2019-01-07</td>\n      <td>2019-01-07</td>\n    </tr>\n    <tr>\n      <th>trip_start_hr_15</th>\n      <td>00_0</td>\n      <td>00_0</td>\n    </tr>\n    <tr>\n      <th>rte</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>dir</th>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>day_of_week</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>is_ns</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>is_rapid</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>is_weekend</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>orca_total</th>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>frac_disabled</th>\n      <td>0.0666667</td>\n      <td>0.00641026</td>\n    </tr>\n    <tr>\n      <th>frac_youth</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>frac_senior</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>frac_li</th>\n      <td>0</td>\n      <td>0.0128205</td>\n    </tr>\n    <tr>\n      <th>frac_uw</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ons</th>\n      <td>5</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>region</th>\n      <td>Seattle</td>\n      <td>Seattle</td>\n    </tr>\n    <tr>\n      <th>start</th>\n      <td>Kinnear</td>\n      <td>West Queen Anne</td>\n    </tr>\n    <tr>\n      <th>end</th>\n      <td>Downtown Seattle</td>\n      <td>Madrona</td>\n    </tr>\n    <tr>\n      <th>type</th>\n      <td>Trolley</td>\n      <td>Trolley</td>\n    </tr>\n    <tr>\n      <th>summer</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                 0                1\nopd_date                2019-01-07       2019-01-07\ntrip_start_hr_15              00_0             00_0\nrte                              1                2\ndir                              N                N\nday_of_week                      0                0\nis_ns                            1                1\nis_rapid                         0                0\nis_weekend                       0                0\norca_total                       2                3\nfrac_disabled            0.0666667       0.00641026\nfrac_youth                       0                0\nfrac_senior                      0                0\nfrac_li                          0        0.0128205\nfrac_uw                          0                0\nons                              5               16\nregion                     Seattle          Seattle\nstart                      Kinnear  West Queen Anne\nend               Downtown Seattle          Madrona\ntype                       Trolley          Trolley\nsummer                       False            False"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare training and xval data\n",
    "TRAINING_FILE, XVAL_FILE = \"../combined_data/15min/train.tsv.gz\", \"../combined_data/15min/xval.tsv.gz\"\n",
    "train, xval = pd.read_csv(TRAINING_FILE, sep='\\t'), pd.read_csv(XVAL_FILE, sep='\\t')\n",
    "print(f'Training dimension: {train.shape}')\n",
    "print(f'Xval dimension: {xval.shape}')\n",
    "print('\\n'.join(train.columns))\n",
    "train.head(n=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_NUM_COLS = [\n",
    "    'orca_total', 'frac_disabled', 'frac_youth', 'frac_senior', 'frac_li', 'frac_uw'\n",
    "]\n",
    "X_CAT_COLS = ['is_ns', 'is_rapid', 'is_weekend', 'trip_start_hr_15', 'rte', 'dir', 'day_of_week', 'region', 'start', 'end', 'summer']\n",
    "\n",
    "\n",
    "label_encoders = {col: LabelEncoder() for col in X_CAT_COLS}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.concatenate((\n",
    "    scaler.fit_transform(train[X_NUM_COLS]),\n",
    "    one_hot_encoder.fit_transform(\n",
    "        np.stack([label_encoders[col].fit_transform(train[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "X_xval = np.concatenate((\n",
    "    scaler.transform(xval[X_NUM_COLS]),\n",
    "    one_hot_encoder.transform(\n",
    "        np.stack([label_encoders[col].transform(xval[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "\n",
    "y_train = train['ons']\n",
    "y_xval = xval['ons']\n",
    "\n",
    "column_labels = list()\n",
    "column_labels.extend(X_NUM_COLS)\n",
    "for cat in X_CAT_COLS:\n",
    "    for clazz in label_encoders[cat].classes_:\n",
    "        column_labels.append(f'{cat}: {clazz}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "orca_total: [[-0.76657383 -0.72243036 -0.45756958 -0.85486075 -0.6782869 ]]\nfrac_disabled: [[ 1.36376967 -0.41035794 -0.54689108 -0.59909492  0.01430026]]\nfrac_youth: [[-0.50030876 -0.50030876 -0.50030876 -0.50030876 -0.50030876]]\nfrac_senior: [[-0.53708954 -0.53708954 -0.53708954 -0.53708954 -0.53708954]]\nfrac_li: [[-0.65231668 -0.30054282 -0.31176964 -0.65231668 -0.65231668]]\nfrac_uw: [[-0.4245457  -0.4245457  -0.2131194  -0.4245457  -0.01050253]]\nis_ns: 0.0: [[0. 0. 0. 0. 0.]]\nis_ns: 1.0: [[1. 1. 1. 1. 1.]]\nis_rapid: 0.0: [[1. 1. 1. 1. 1.]]\nis_rapid: 1.0: [[0. 0. 0. 0. 0.]]\nis_weekend: 0.0: [[1. 1. 1. 1. 1.]]\nis_weekend: 1.0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 00_0: [[1. 1. 1. 1. 1.]]\ntrip_start_hr_15: 00_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 00_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 00_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 01_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 01_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 01_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 01_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 02_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 02_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 02_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 02_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 03_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 03_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 03_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 03_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 04_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 04_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 04_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 04_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 05_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 05_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 05_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 05_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 06_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 06_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 06_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 06_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 07_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 07_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 07_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 07_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 08_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 08_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 08_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 08_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 09_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 09_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 09_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 09_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 10_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 10_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 10_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 10_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 11_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 11_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 11_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 11_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 12_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 12_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 12_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 12_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 13_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 13_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 13_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 13_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 14_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 14_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 14_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 14_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 15_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 15_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 15_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 15_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 16_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 16_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 16_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 16_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 17_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 17_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 17_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 17_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 18_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 18_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 18_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 18_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 19_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 19_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 19_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 19_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 20_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 20_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 20_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 20_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 21_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 21_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 21_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 21_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 22_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 22_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 22_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 22_45: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 23_0: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 23_15: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 23_30: [[0. 0. 0. 0. 0.]]\ntrip_start_hr_15: 23_45: [[0. 0. 0. 0. 0.]]\nrte: 1: [[1. 0. 0. 0. 0.]]\nrte: 2: [[0. 1. 1. 0. 0.]]\nrte: 3: [[0. 0. 0. 1. 1.]]\nrte: 4: [[0. 0. 0. 0. 0.]]\nrte: 5: [[0. 0. 0. 0. 0.]]\nrte: 7: [[0. 0. 0. 0. 0.]]\nrte: 8: [[0. 0. 0. 0. 0.]]\nrte: 9: [[0. 0. 0. 0. 0.]]\nrte: 10: [[0. 0. 0. 0. 0.]]\nrte: 11: [[0. 0. 0. 0. 0.]]\nrte: 12: [[0. 0. 0. 0. 0.]]\nrte: 13: [[0. 0. 0. 0. 0.]]\nrte: 14: [[0. 0. 0. 0. 0.]]\nrte: 15: [[0. 0. 0. 0. 0.]]\nrte: 17: [[0. 0. 0. 0. 0.]]\nrte: 18: [[0. 0. 0. 0. 0.]]\nrte: 19: [[0. 0. 0. 0. 0.]]\nrte: 21: [[0. 0. 0. 0. 0.]]\nrte: 22: [[0. 0. 0. 0. 0.]]\nrte: 24: [[0. 0. 0. 0. 0.]]\nrte: 26: [[0. 0. 0. 0. 0.]]\nrte: 27: [[0. 0. 0. 0. 0.]]\nrte: 28: [[0. 0. 0. 0. 0.]]\nrte: 29: [[0. 0. 0. 0. 0.]]\nrte: 31: [[0. 0. 0. 0. 0.]]\nrte: 32: [[0. 0. 0. 0. 0.]]\nrte: 33: [[0. 0. 0. 0. 0.]]\nrte: 36: [[0. 0. 0. 0. 0.]]\nrte: 37: [[0. 0. 0. 0. 0.]]\nrte: 40: [[0. 0. 0. 0. 0.]]\nrte: 41: [[0. 0. 0. 0. 0.]]\nrte: 43: [[0. 0. 0. 0. 0.]]\nrte: 44: [[0. 0. 0. 0. 0.]]\nrte: 45: [[0. 0. 0. 0. 0.]]\nrte: 47: [[0. 0. 0. 0. 0.]]\nrte: 48: [[0. 0. 0. 0. 0.]]\nrte: 49: [[0. 0. 0. 0. 0.]]\nrte: 50: [[0. 0. 0. 0. 0.]]\nrte: 55: [[0. 0. 0. 0. 0.]]\nrte: 56: [[0. 0. 0. 0. 0.]]\nrte: 57: [[0. 0. 0. 0. 0.]]\nrte: 60: [[0. 0. 0. 0. 0.]]\nrte: 62: [[0. 0. 0. 0. 0.]]\nrte: 63: [[0. 0. 0. 0. 0.]]\nrte: 64: [[0. 0. 0. 0. 0.]]\nrte: 65: [[0. 0. 0. 0. 0.]]\nrte: 67: [[0. 0. 0. 0. 0.]]\nrte: 70: [[0. 0. 0. 0. 0.]]\nrte: 71: [[0. 0. 0. 0. 0.]]\nrte: 73: [[0. 0. 0. 0. 0.]]\nrte: 74: [[0. 0. 0. 0. 0.]]\nrte: 75: [[0. 0. 0. 0. 0.]]\nrte: 76: [[0. 0. 0. 0. 0.]]\nrte: 77: [[0. 0. 0. 0. 0.]]\nrte: 78: [[0. 0. 0. 0. 0.]]\nrte: 101: [[0. 0. 0. 0. 0.]]\nrte: 102: [[0. 0. 0. 0. 0.]]\nrte: 105: [[0. 0. 0. 0. 0.]]\nrte: 106: [[0. 0. 0. 0. 0.]]\nrte: 107: [[0. 0. 0. 0. 0.]]\nrte: 111: [[0. 0. 0. 0. 0.]]\nrte: 113: [[0. 0. 0. 0. 0.]]\nrte: 114: [[0. 0. 0. 0. 0.]]\nrte: 116: [[0. 0. 0. 0. 0.]]\nrte: 118: [[0. 0. 0. 0. 0.]]\nrte: 119: [[0. 0. 0. 0. 0.]]\nrte: 120: [[0. 0. 0. 0. 0.]]\nrte: 121: [[0. 0. 0. 0. 0.]]\nrte: 122: [[0. 0. 0. 0. 0.]]\nrte: 123: [[0. 0. 0. 0. 0.]]\nrte: 124: [[0. 0. 0. 0. 0.]]\nrte: 125: [[0. 0. 0. 0. 0.]]\nrte: 128: [[0. 0. 0. 0. 0.]]\nrte: 131: [[0. 0. 0. 0. 0.]]\nrte: 132: [[0. 0. 0. 0. 0.]]\nrte: 143: [[0. 0. 0. 0. 0.]]\nrte: 148: [[0. 0. 0. 0. 0.]]\nrte: 150: [[0. 0. 0. 0. 0.]]\nrte: 153: [[0. 0. 0. 0. 0.]]\nrte: 154: [[0. 0. 0. 0. 0.]]\nrte: 156: [[0. 0. 0. 0. 0.]]\nrte: 157: [[0. 0. 0. 0. 0.]]\nrte: 158: [[0. 0. 0. 0. 0.]]\nrte: 159: [[0. 0. 0. 0. 0.]]\nrte: 164: [[0. 0. 0. 0. 0.]]\nrte: 166: [[0. 0. 0. 0. 0.]]\nrte: 167: [[0. 0. 0. 0. 0.]]\nrte: 168: [[0. 0. 0. 0. 0.]]\nrte: 169: [[0. 0. 0. 0. 0.]]\nrte: 177: [[0. 0. 0. 0. 0.]]\nrte: 178: [[0. 0. 0. 0. 0.]]\nrte: 179: [[0. 0. 0. 0. 0.]]\nrte: 180: [[0. 0. 0. 0. 0.]]\nrte: 181: [[0. 0. 0. 0. 0.]]\nrte: 182: [[0. 0. 0. 0. 0.]]\nrte: 183: [[0. 0. 0. 0. 0.]]\nrte: 186: [[0. 0. 0. 0. 0.]]\nrte: 187: [[0. 0. 0. 0. 0.]]\nrte: 190: [[0. 0. 0. 0. 0.]]\nrte: 192: [[0. 0. 0. 0. 0.]]\nrte: 193: [[0. 0. 0. 0. 0.]]\nrte: 197: [[0. 0. 0. 0. 0.]]\nrte: 200: [[0. 0. 0. 0. 0.]]\nrte: 201: [[0. 0. 0. 0. 0.]]\nrte: 204: [[0. 0. 0. 0. 0.]]\nrte: 208: [[0. 0. 0. 0. 0.]]\nrte: 212: [[0. 0. 0. 0. 0.]]\nrte: 214: [[0. 0. 0. 0. 0.]]\nrte: 216: [[0. 0. 0. 0. 0.]]\nrte: 217: [[0. 0. 0. 0. 0.]]\nrte: 218: [[0. 0. 0. 0. 0.]]\nrte: 219: [[0. 0. 0. 0. 0.]]\nrte: 221: [[0. 0. 0. 0. 0.]]\nrte: 224: [[0. 0. 0. 0. 0.]]\nrte: 226: [[0. 0. 0. 0. 0.]]\nrte: 232: [[0. 0. 0. 0. 0.]]\nrte: 234: [[0. 0. 0. 0. 0.]]\nrte: 235: [[0. 0. 0. 0. 0.]]\nrte: 236: [[0. 0. 0. 0. 0.]]\nrte: 237: [[0. 0. 0. 0. 0.]]\nrte: 238: [[0. 0. 0. 0. 0.]]\nrte: 240: [[0. 0. 0. 0. 0.]]\nrte: 241: [[0. 0. 0. 0. 0.]]\nrte: 243: [[0. 0. 0. 0. 0.]]\nrte: 244: [[0. 0. 0. 0. 0.]]\nrte: 245: [[0. 0. 0. 0. 0.]]\nrte: 246: [[0. 0. 0. 0. 0.]]\nrte: 248: [[0. 0. 0. 0. 0.]]\nrte: 249: [[0. 0. 0. 0. 0.]]\nrte: 252: [[0. 0. 0. 0. 0.]]\nrte: 255: [[0. 0. 0. 0. 0.]]\nrte: 257: [[0. 0. 0. 0. 0.]]\nrte: 268: [[0. 0. 0. 0. 0.]]\nrte: 269: [[0. 0. 0. 0. 0.]]\nrte: 271: [[0. 0. 0. 0. 0.]]\nrte: 277: [[0. 0. 0. 0. 0.]]\nrte: 301: [[0. 0. 0. 0. 0.]]\nrte: 303: [[0. 0. 0. 0. 0.]]\nrte: 304: [[0. 0. 0. 0. 0.]]\nrte: 308: [[0. 0. 0. 0. 0.]]\nrte: 309: [[0. 0. 0. 0. 0.]]\nrte: 311: [[0. 0. 0. 0. 0.]]\nrte: 312: [[0. 0. 0. 0. 0.]]\nrte: 316: [[0. 0. 0. 0. 0.]]\nrte: 330: [[0. 0. 0. 0. 0.]]\nrte: 331: [[0. 0. 0. 0. 0.]]\nrte: 342: [[0. 0. 0. 0. 0.]]\nrte: 345: [[0. 0. 0. 0. 0.]]\nrte: 346: [[0. 0. 0. 0. 0.]]\nrte: 347: [[0. 0. 0. 0. 0.]]\nrte: 348: [[0. 0. 0. 0. 0.]]\nrte: 355: [[0. 0. 0. 0. 0.]]\nrte: 372: [[0. 0. 0. 0. 0.]]\nrte: 373: [[0. 0. 0. 0. 0.]]\nrte: 522: [[0. 0. 0. 0. 0.]]\nrte: 540: [[0. 0. 0. 0. 0.]]\nrte: 541: [[0. 0. 0. 0. 0.]]\nrte: 542: [[0. 0. 0. 0. 0.]]\nrte: 545: [[0. 0. 0. 0. 0.]]\nrte: 550: [[0. 0. 0. 0. 0.]]\nrte: 554: [[0. 0. 0. 0. 0.]]\nrte: 555: [[0. 0. 0. 0. 0.]]\nrte: 556: [[0. 0. 0. 0. 0.]]\nrte: 671: [[0. 0. 0. 0. 0.]]\nrte: 672: [[0. 0. 0. 0. 0.]]\nrte: 673: [[0. 0. 0. 0. 0.]]\nrte: 674: [[0. 0. 0. 0. 0.]]\nrte: 675: [[0. 0. 0. 0. 0.]]\nrte: 676: [[0. 0. 0. 0. 0.]]\ndir: E: [[0. 0. 0. 0. 0.]]\ndir: N: [[1. 1. 0. 1. 0.]]\ndir: S: [[0. 0. 1. 0. 1.]]\ndir: W: [[0. 0. 0. 0. 0.]]\nday_of_week: 0: [[1. 1. 1. 1. 1.]]\nday_of_week: 1: [[0. 0. 0. 0. 0.]]\nday_of_week: 2: [[0. 0. 0. 0. 0.]]\nday_of_week: 3: [[0. 0. 0. 0. 0.]]\nday_of_week: 4: [[0. 0. 0. 0. 0.]]\nday_of_week: 5: [[0. 0. 0. 0. 0.]]\nday_of_week: 6: [[0. 0. 0. 0. 0.]]\nregion: East King County: [[0. 0. 0. 0. 0.]]\nregion: Express: [[0. 0. 0. 0. 0.]]\nregion: North King County: [[0. 0. 0. 0. 0.]]\nregion: Seattle: [[1. 1. 1. 1. 1.]]\nregion: South King County: [[0. 0. 0. 0. 0.]]\nstart: Admiral District: [[0. 0. 0. 0. 0.]]\nstart: Alaska Junction: [[0. 0. 0. 0. 0.]]\nstart: Alki Point: [[0. 0. 0. 0. 0.]]\nstart: Auburn Station: [[0. 0. 0. 0. 0.]]\nstart: Aurora Village Transit Center: [[0. 0. 0. 0. 0.]]\nstart: Ballard: [[0. 0. 0. 0. 0.]]\nstart: Beacon Hill station: [[0. 0. 0. 0. 0.]]\nstart: Bellevue: [[0. 0. 0. 0. 0.]]\nstart: Blue Ridge: [[0. 0. 0. 0. 0.]]\nstart: Brickyard P&R: [[0. 0. 0. 0. 0.]]\nstart: Burien Transit Center: [[0. 0. 0. 0. 0.]]\nstart: Capitol Hill: [[0. 0. 0. 0. 0.]]\nstart: Carkeek Park: [[0. 0. 0. 0. 0.]]\nstart: Central Magnolia: [[0. 0. 0. 0. 0.]]\nstart: Children's Hospital: [[0. 0. 0. 0. 0.]]\nstart: Crown Hill: [[0. 0. 0. 0. 0.]]\nstart: Downtown Seattle: [[0. 0. 0. 0. 0.]]\nstart: Duvall: [[0. 0. 0. 0. 0.]]\nstart: East Magnolia: [[0. 0. 0. 0. 0.]]\nstart: Eastgate P&R: [[0. 0. 0. 0. 0.]]\nstart: Federal Center South: [[0. 0. 0. 0. 0.]]\nstart: Federal Way: [[0. 0. 0. 0. 0.]]\nstart: First Hill: [[0. 0. 0. 0. 0.]]\nstart: Green Lake: [[0. 0. 0. 0. 0.]]\nstart: Highline College: [[0. 0. 0. 0. 0.]]\nstart: International District/Chinatown station: [[0. 0. 0. 0. 0.]]\nstart: Issaquah: [[0. 0. 0. 0. 0.]]\nstart: Jackson Park: [[0. 0. 0. 0. 0.]]\nstart: Juanita: [[0. 0. 0. 0. 0.]]\nstart: Kenmore: [[0. 0. 0. 0. 0.]]\nstart: Kent Station: [[0. 0. 0. 0. 0.]]\nstart: Kingsgate: [[0. 0. 0. 0. 0.]]\nstart: Kinnear: [[1. 0. 0. 0. 0.]]\nstart: Kirkland Transit Center: [[0. 0. 0. 0. 0.]]\nstart: Lake City: [[0. 0. 0. 0. 0.]]\nstart: Lake Meridian P&R: [[0. 0. 0. 0. 0.]]\nstart: Loyal Heights: [[0. 0. 0. 0. 0.]]\nstart: North Beach: [[0. 0. 0. 0. 0.]]\nstart: North City: [[0. 0. 0. 0. 0.]]\nstart: North Mercer Island: [[0. 0. 0. 0. 0.]]\nstart: Northgate Transit Center: [[0. 0. 0. 0. 0.]]\nstart: Overlake: [[0. 0. 0. 0. 0.]]\nstart: Redmond: [[0. 0. 0. 0. 0.]]\nstart: Renton: [[0. 0. 0. 0. 0.]]\nstart: Sand Point: [[0. 0. 0. 0. 0.]]\nstart: Seattle Center: [[0. 0. 0. 0. 0.]]\nstart: Seattle Pacific University: [[0. 0. 0. 1. 1.]]\nstart: Shoreline: [[0. 0. 0. 0. 0.]]\nstart: South Lake Union: [[0. 0. 0. 0. 0.]]\nstart: Sunset Hill: [[0. 0. 0. 0. 0.]]\nstart: Tukwila: [[0. 0. 0. 0. 0.]]\nstart: Twin Lakes: [[0. 0. 0. 0. 0.]]\nstart: University District: [[0. 0. 0. 0. 0.]]\nstart: Unknown: [[0. 0. 0. 0. 0.]]\nstart: Vashon Island Ferry Terminal: [[0. 0. 0. 0. 0.]]\nstart: Wedgwood: [[0. 0. 0. 0. 0.]]\nstart: West Magnolia: [[0. 0. 0. 0. 0.]]\nstart: West Queen Anne: [[0. 1. 1. 0. 0.]]\nstart: West Seattle: [[0. 0. 0. 0. 0.]]\nend: Arbor Heights: [[0. 0. 0. 0. 0.]]\nend: Aurora Village Transit Center: [[0. 0. 0. 0. 0.]]\nend: Avondale: [[0. 0. 0. 0. 0.]]\nend: Bear Creek P&R: [[0. 0. 0. 0. 0.]]\nend: Bellevue: [[0. 0. 0. 0. 0.]]\nend: Black Diamond: [[0. 0. 0. 0. 0.]]\nend: Bothell: [[0. 0. 0. 0. 0.]]\nend: Burien Transit Center: [[0. 0. 0. 0. 0.]]\nend: Capitol Hill: [[0. 0. 0. 0. 0.]]\nend: Cherry Hill: [[0. 0. 0. 0. 0.]]\nend: Children's Hospital: [[0. 0. 0. 0. 0.]]\nend: Clyde Hill: [[0. 0. 0. 0. 0.]]\nend: Colman Park: [[0. 0. 0. 0. 0.]]\nend: Dockton: [[0. 0. 0. 0. 0.]]\nend: Downtown Seattle: [[1. 0. 0. 0. 0.]]\nend: Eastgate P&R: [[0. 0. 0. 0. 0.]]\nend: Education Hill: [[0. 0. 0. 0. 0.]]\nend: Enumclaw: [[0. 0. 0. 0. 0.]]\nend: Factoria: [[0. 0. 0. 0. 0.]]\nend: Fairwood: [[0. 0. 0. 0. 0.]]\nend: Fauntleroy Ferry Terminal: [[0. 0. 0. 0. 0.]]\nend: Federal Way: [[0. 0. 0. 0. 0.]]\nend: Green River College: [[0. 0. 0. 0. 0.]]\nend: Highline College: [[0. 0. 0. 0. 0.]]\nend: Horizon View: [[0. 0. 0. 0. 0.]]\nend: Interlaken Park: [[0. 0. 0. 0. 0.]]\nend: Issaquah: [[0. 0. 0. 0. 0.]]\nend: Judkins Park: [[0. 0. 0. 0. 0.]]\nend: Kenmore: [[0. 0. 0. 0. 0.]]\nend: Kent Station: [[0. 0. 0. 0. 0.]]\nend: Kingsgate: [[0. 0. 0. 0. 0.]]\nend: Kirkland Transit Center: [[0. 0. 0. 0. 0.]]\nend: Lake Kathleen: [[0. 0. 0. 0. 0.]]\nend: Lake Meridian P&R: [[0. 0. 0. 0. 0.]]\nend: Madison Park: [[0. 0. 0. 0. 0.]]\nend: Madrona: [[0. 1. 1. 1. 1.]]\nend: Maple Valley: [[0. 0. 0. 0. 0.]]\nend: Meridian Park: [[0. 0. 0. 0. 0.]]\nend: Mount Baker: [[0. 0. 0. 0. 0.]]\nend: Mountlake Terrace Transit Center: [[0. 0. 0. 0. 0.]]\nend: North Bend: [[0. 0. 0. 0. 0.]]\nend: North Issaquah: [[0. 0. 0. 0. 0.]]\nend: Northeast Tacoma (crosses into Pierce County): [[0. 0. 0. 0. 0.]]\nend: Othello Station: [[0. 0. 0. 0. 0.]]\nend: Overlake: [[0. 0. 0. 0. 0.]]\nend: Rainier Beach: [[0. 0. 0. 0. 0.]]\nend: Rainier Beach station: [[0. 0. 0. 0. 0.]]\nend: Redmond: [[0. 0. 0. 0. 0.]]\nend: Redondo Heights P&R: [[0. 0. 0. 0. 0.]]\nend: Renton: [[0. 0. 0. 0. 0.]]\nend: Richmond Beach: [[0. 0. 0. 0. 0.]]\nend: Sand Point: [[0. 0. 0. 0. 0.]]\nend: Seahurst: [[0. 0. 0. 0. 0.]]\nend: Shoreline: [[0. 0. 0. 0. 0.]]\nend: Shorewood: [[0. 0. 0. 0. 0.]]\nend: South Bellevue P&R: [[0. 0. 0. 0. 0.]]\nend: South Federal Way P&R: [[0. 0. 0. 0. 0.]]\nend: South Mercer Island: [[0. 0. 0. 0. 0.]]\nend: South Renton P&R: [[0. 0. 0. 0. 0.]]\nend: Southcenter: [[0. 0. 0. 0. 0.]]\nend: Southeast Auburn: [[0. 0. 0. 0. 0.]]\nend: Star Lake P&R: [[0. 0. 0. 0. 0.]]\nend: Summit: [[0. 0. 0. 0. 0.]]\nend: Swedish Medical Center Issaquah: [[0. 0. 0. 0. 0.]]\nend: Tahlequah Ferry Terminal: [[0. 0. 0. 0. 0.]]\nend: Timberlane: [[0. 0. 0. 0. 0.]]\nend: Tukwila: [[0. 0. 0. 0. 0.]]\nend: Twin Lakes: [[0. 0. 0. 0. 0.]]\nend: University District: [[0. 0. 0. 0. 0.]]\nend: Unknown: [[0. 0. 0. 0. 0.]]\nend: Westwood Village: [[0. 0. 0. 0. 0.]]\nend: Woodinville: [[0. 0. 0. 0. 0.]]\nsummer: False: [[1. 1. 1. 1. 1.]]\nsummer: True: [[0. 0. 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "assert len(column_labels) == X_train.shape[1]\n",
    "\n",
    "for i, label in enumerate(column_labels):\n",
    "    print(f'{label}: {np.squeeze(X_train[:5, i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1 middle layers\nEpoch 1/10\n542954/542954 [==============================] - 9s 17us/step - loss: 13.4350 - mean_absolute_error: 13.4350 - mean_squared_error: 586.5932\nEpoch 2/10\n542954/542954 [==============================] - 7s 14us/step - loss: 13.2179 - mean_absolute_error: 13.2179 - mean_squared_error: 571.8288\nEpoch 3/10\n542954/542954 [==============================] - 7s 14us/step - loss: 13.2228 - mean_absolute_error: 13.2228 - mean_squared_error: 574.3151\nEpoch 4/10\n542954/542954 [==============================] - 7s 14us/step - loss: 13.2007 - mean_absolute_error: 13.2007 - mean_squared_error: 567.6453\nEpoch 5/10\n542954/542954 [==============================] - 8s 14us/step - loss: 13.2090 - mean_absolute_error: 13.2090 - mean_squared_error: 572.9196\nEpoch 6/10\n542954/542954 [==============================] - 8s 14us/step - loss: 13.2216 - mean_absolute_error: 13.2216 - mean_squared_error: 571.7853\nEpoch 7/10\n542954/542954 [==============================] - 8s 14us/step - loss: 13.2207 - mean_absolute_error: 13.2207 - mean_squared_error: 572.7233\nEpoch 8/10\n542954/542954 [==============================] - 8s 14us/step - loss: 13.1902 - mean_absolute_error: 13.1902 - mean_squared_error: 566.8093\nEpoch 9/10\n542954/542954 [==============================] - 8s 14us/step - loss: 13.1909 - mean_absolute_error: 13.1909 - mean_squared_error: 569.6072\nEpoch 10/10\n542954/542954 [==============================] - 8s 14us/step - loss: 13.1984 - mean_absolute_error: 13.1984 - mean_squared_error: 568.9017\n67876/67876 [==============================] - 1s 17us/step\n9.860205568023265\n2 middle layers\nEpoch 1/10\n542954/542954 [==============================] - 11s 21us/step - loss: 17.7219 - mean_absolute_error: 17.7219 - mean_squared_error: 897.2574\nEpoch 2/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.5780 - mean_absolute_error: 17.5780 - mean_squared_error: 886.2735\nEpoch 3/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.6718 - mean_absolute_error: 17.6718 - mean_squared_error: 895.8833\nEpoch 4/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.6896 - mean_absolute_error: 17.6896 - mean_squared_error: 900.6779\nEpoch 5/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.8079 - mean_absolute_error: 17.8079 - mean_squared_error: 909.3250\nEpoch 6/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.7882 - mean_absolute_error: 17.7882 - mean_squared_error: 911.6730\nEpoch 7/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.7267 - mean_absolute_error: 17.7267 - mean_squared_error: 910.2892\nEpoch 8/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.9079 - mean_absolute_error: 17.9079 - mean_squared_error: 890.8614\nEpoch 9/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.9042 - mean_absolute_error: 17.9042 - mean_squared_error: 909.0018\nEpoch 10/10\n542954/542954 [==============================] - 10s 18us/step - loss: 17.8937 - mean_absolute_error: 17.8937 - mean_squared_error: 914.1802\n67876/67876 [==============================] - 1s 19us/step\n15.237501715748275\n4 middle layers\nEpoch 1/10\n542954/542954 [==============================] - 16s 29us/step - loss: 21.3301 - mean_absolute_error: 21.3301 - mean_squared_error: 1218.6656\nEpoch 2/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.7661 - mean_absolute_error: 20.7661 - mean_squared_error: 1170.2747\nEpoch 3/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.7112 - mean_absolute_error: 20.7112 - mean_squared_error: 1156.7508\nEpoch 4/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.6940 - mean_absolute_error: 20.6940 - mean_squared_error: 1168.8159\nEpoch 5/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.6230 - mean_absolute_error: 20.6230 - mean_squared_error: 1172.5666\nEpoch 6/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.5403 - mean_absolute_error: 20.5403 - mean_squared_error: 1155.1028\nEpoch 7/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.6349 - mean_absolute_error: 20.6349 - mean_squared_error: 1148.5211\nEpoch 8/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.6723 - mean_absolute_error: 20.6723 - mean_squared_error: 1141.1251\nEpoch 9/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.7036 - mean_absolute_error: 20.7036 - mean_squared_error: 1159.2726\nEpoch 10/10\n542954/542954 [==============================] - 13s 25us/step - loss: 20.8094 - mean_absolute_error: 20.8094 - mean_squared_error: 1176.5216\n67876/67876 [==============================] - 2s 23us/step\n17.95892187204293\n8 middle layers\nEpoch 1/10\n542954/542954 [==============================] - 24s 44us/step - loss: 23.1091 - mean_absolute_error: 23.1091 - mean_squared_error: 1382.8680\nEpoch 2/10\n542954/542954 [==============================] - 21s 39us/step - loss: 22.9873 - mean_absolute_error: 22.9873 - mean_squared_error: 1368.7485\nEpoch 3/10\n542954/542954 [==============================] - 21s 39us/step - loss: 22.9871 - mean_absolute_error: 22.9871 - mean_squared_error: 1368.0923\nEpoch 4/10\n542954/542954 [==============================] - 21s 39us/step - loss: 22.9856 - mean_absolute_error: 22.9856 - mean_squared_error: 1368.4981\nEpoch 5/10\n542954/542954 [==============================] - 21s 38us/step - loss: 22.9862 - mean_absolute_error: 22.9862 - mean_squared_error: 1368.7183\nEpoch 6/10\n542954/542954 [==============================] - 21s 39us/step - loss: 22.9864 - mean_absolute_error: 22.9864 - mean_squared_error: 1368.1638\nEpoch 7/10\n542954/542954 [==============================] - 21s 39us/step - loss: 22.9863 - mean_absolute_error: 22.9863 - mean_squared_error: 1368.4592\nEpoch 8/10\n542954/542954 [==============================] - 21s 38us/step - loss: 22.9858 - mean_absolute_error: 22.9858 - mean_squared_error: 1368.3973\nEpoch 9/10\n542954/542954 [==============================] - 21s 38us/step - loss: 22.9856 - mean_absolute_error: 22.9856 - mean_squared_error: 1368.1418\nEpoch 10/10\n542954/542954 [==============================] - 21s 38us/step - loss: 22.9864 - mean_absolute_error: 22.9864 - mean_squared_error: 1368.5256\n67876/67876 [==============================] - 2s 29us/step\n22.89282713942961\n10 middle layers\nEpoch 1/10\n542954/542954 [==============================] - 29s 53us/step - loss: 23.1146 - mean_absolute_error: 23.1146 - mean_squared_error: 1382.5612\nEpoch 2/10\n542954/542954 [==============================] - 25s 45us/step - loss: 22.9869 - mean_absolute_error: 22.9869 - mean_squared_error: 1368.3368\nEpoch 3/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9859 - mean_absolute_error: 22.9859 - mean_squared_error: 1368.4427\nEpoch 4/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9854 - mean_absolute_error: 22.9854 - mean_squared_error: 1367.9209\nEpoch 5/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9840 - mean_absolute_error: 22.9840 - mean_squared_error: 1368.0990\nEpoch 6/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9839 - mean_absolute_error: 22.9839 - mean_squared_error: 1367.9193\nEpoch 7/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9841 - mean_absolute_error: 22.9841 - mean_squared_error: 1368.3197\nEpoch 8/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9838 - mean_absolute_error: 22.9838 - mean_squared_error: 1368.3666\nEpoch 9/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9840 - mean_absolute_error: 22.9840 - mean_squared_error: 1367.2070\nEpoch 10/10\n542954/542954 [==============================] - 25s 46us/step - loss: 22.9827 - mean_absolute_error: 22.9827 - mean_squared_error: 1367.1431\n67876/67876 [==============================] - 2s 34us/step\n22.887278550135814\n"
    }
   ],
   "source": [
    "# Attempt 1: long thin neural net\n",
    "xval_perf = list()\n",
    "for n_middle_layers in (1,2,4,8,10):\n",
    "    print(f\"{n_middle_layers} middle layers\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, activation=\"linear\", input_dim=426))\n",
    "    model.add(Dropout(0.5))\n",
    "    for i in range(n_middle_layers-1):\n",
    "        model.add(Dense(4, activation='sigmoid'))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=256)\n",
    "    xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "    xval_perf.append(xval_mae)\n",
    "    print(xval_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[9.860205568023265,\n 15.237501715748275,\n 17.95892187204293,\n 22.89282713942961,\n 22.887278550135814]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xval_perf   # 9.86 is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning approach. Train a neural net to classify up to n clusters.\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.random import uniform, seed\n",
    "\n",
    "n_clusters = 24\n",
    "# Best I could do at 6: 21 mae on training\n",
    "\n",
    "seed(10)\n",
    "X_samp = X_train[uniform(size=X_train.shape[0]) < 0.1,:]\n",
    "kmeans = KMeans(n_clusters, n_jobs=-1)\n",
    "cluster_preds = kmeans.fit_predict(X_samp)\n",
    "X_classes = kmeans.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3     44631\n13    39301\n1     39136\n19    37222\n0     33689\n4     33535\n12    31647\n14    31437\n17    30908\n9     30571\n11    28349\n16    22873\n6     20808\n2     20480\n20    19412\n5     15292\n22    11544\n15     9966\n18     9062\n7      8623\n8      7331\n23     6517\n21     5576\n10     5044\ndtype: int64"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(X_classes).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/5\n542954/542954 [==============================] - 33s 62us/step - loss: 0.1678 - acc: 0.9583\nEpoch 2/5\n542954/542954 [==============================] - 31s 57us/step - loss: 0.1623 - acc: 0.9583\nEpoch 3/5\n542954/542954 [==============================] - 31s 56us/step - loss: 0.1469 - acc: 0.9583\nEpoch 4/5\n542954/542954 [==============================] - 31s 57us/step - loss: 0.1357 - acc: 0.9583\nEpoch 5/5\n542954/542954 [==============================] - 31s 57us/step - loss: 0.1309 - acc: 0.9584\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a47b82dd8>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(32, activation=\"relu\", input_dim=X_train.shape[1]))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(n_clusters, activation='sigmoid'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(n_clusters, activation='sigmoid'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(n_clusters, activation='softmax'))\n",
    "\n",
    "classifier.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    #optimizer='adam',\n",
    "    optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "classifier.fit(\n",
    "    X_train, \n",
    "    np_utils.to_categorical(X_classes), \n",
    "    epochs=5, \n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictor = Sequential()\n",
    "# predictor.add(Dense(4, activation=\"relu\", input_dim=n_clusters))\n",
    "# predictor.add(Dropout(0.5))\n",
    "# predictor.add(Dense(4, activation=\"sigmoid\"))\n",
    "# predictor.add(Dropout(0.5))\n",
    "# predictor.add(Dense(4, activation=\"sigmoid\"))\n",
    "# predictor.add(Dropout(0.5))\n",
    "# predictor.add(Dense(1, activation=\"linear\"))\n",
    "# \n",
    "# predictor.compile(\n",
    "#     loss='mean_absolute_error', \n",
    "#     optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "#     metrics=['mean_squared_error']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_train_fwd = classifier.predict(X_train)  # (n, n_clusters)\n",
    "#predictor.fit(X_train_fwd, y_train, epochs=15, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(542954, 30)\n"
    }
   ],
   "source": [
    "X_train_nums = X_train[:,:len(X_NUM_COLS)]\n",
    "X_train_fwd = np.concatenate([classifier.predict(X_train), X_train_nums], axis=1)  # (n, n_clusters + len(X_NUM_COLS))\n",
    "print(X_train_fwd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/20\n542954/542954 [==============================] - 15s 27us/step - loss: 20.8099 - mean_squared_error: 1176.8815\nEpoch 2/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.8858 - mean_squared_error: 1075.9795\nEpoch 3/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.7547 - mean_squared_error: 1076.0079\nEpoch 4/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.7005 - mean_squared_error: 1075.1803\nEpoch 5/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.8009 - mean_squared_error: 1073.6226\nEpoch 6/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.8341 - mean_squared_error: 1080.8641\nEpoch 7/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.5889 - mean_squared_error: 1055.1840\nEpoch 8/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.5703 - mean_squared_error: 1052.4492\nEpoch 9/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.5114 - mean_squared_error: 1057.6304\nEpoch 10/20\n542954/542954 [==============================] - 12s 23us/step - loss: 19.5560 - mean_squared_error: 1058.5958\nEpoch 11/20\n542954/542954 [==============================] - 12s 23us/step - loss: 19.5169 - mean_squared_error: 1056.5457\nEpoch 12/20\n542954/542954 [==============================] - 12s 23us/step - loss: 19.7104 - mean_squared_error: 1080.7637\nEpoch 13/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.6134 - mean_squared_error: 1055.6665\nEpoch 14/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.7570 - mean_squared_error: 1060.5724\nEpoch 15/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.7457 - mean_squared_error: 1061.5489\nEpoch 16/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.7813 - mean_squared_error: 1071.9709\nEpoch 17/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.8710 - mean_squared_error: 1076.0368\nEpoch 18/20\n542954/542954 [==============================] - 12s 22us/step - loss: 19.8793 - mean_squared_error: 1071.0041\nEpoch 19/20\n542954/542954 [==============================] - 12s 23us/step - loss: 19.8971 - mean_squared_error: 1079.8774\nEpoch 20/20\n542954/542954 [==============================] - 12s 23us/step - loss: 20.3079 - mean_squared_error: 1112.4592\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a5b706630>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So that didn't work the way I wanted. Let's add the numeric variables back in addition to the classifier outputs\n",
    "predictor = Sequential()\n",
    "predictor.add(Dense(4, activation=\"relu\", input_dim=X_train_fwd.shape[1]))\n",
    "predictor.add(Dropout(0.3))\n",
    "predictor.add(Dense(4, activation=\"tanh\"))\n",
    "predictor.add(Dropout(0.3))\n",
    "predictor.add(Dense(2, activation=\"sigmoid\"))\n",
    "predictor.add(Dropout(0.3))\n",
    "predictor.add(Dense(2, activation=\"sigmoid\"))\n",
    "predictor.add(Dropout(0.3))\n",
    "predictor.add(Dense(1, activation=\"linear\"))\n",
    "predictor.compile(\n",
    "    loss='mean_absolute_error', \n",
    "    optimizer=SGD(lr=0.05, decay=1e-5, momentum=0.9, nesterov=True), \n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "\n",
    "predictor.fit(X_train_fwd, y_train, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "67876/67876 [==============================] - 2s 23us/step\n"
    },
    {
     "data": {
      "text/plain": "19.639980235682316"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward = np.concatenate([classifier.predict(X_xval), X_xval[:,:len(X_NUM_COLS)]], axis=1)\n",
    "predictor.evaluate(forward, y_xval, batch_size=128)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/20\n542954/542954 [==============================] - 12s 22us/step - loss: 17.6996 - mean_squared_error: 945.0755\nEpoch 2/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.9535 - mean_squared_error: 873.0365\nEpoch 3/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.9322 - mean_squared_error: 872.8653\nEpoch 4/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.9046 - mean_squared_error: 872.2459\nEpoch 5/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.9202 - mean_squared_error: 872.5690\nEpoch 6/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.9241 - mean_squared_error: 873.3550\nEpoch 7/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.9030 - mean_squared_error: 871.6740\nEpoch 8/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.9024 - mean_squared_error: 869.1037\nEpoch 9/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.8562 - mean_squared_error: 868.2405\nEpoch 10/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.8555 - mean_squared_error: 866.1473\nEpoch 11/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8442 - mean_squared_error: 865.9513\nEpoch 12/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8369 - mean_squared_error: 865.3676\nEpoch 13/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8191 - mean_squared_error: 862.8372\nEpoch 14/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8321 - mean_squared_error: 866.3488\nEpoch 15/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8366 - mean_squared_error: 864.1658\nEpoch 16/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8380 - mean_squared_error: 864.8459\nEpoch 17/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.8153 - mean_squared_error: 862.4557\nEpoch 18/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.8232 - mean_squared_error: 863.6359\nEpoch 19/20\n542954/542954 [==============================] - 9s 17us/step - loss: 16.8028 - mean_squared_error: 862.3150\nEpoch 20/20\n542954/542954 [==============================] - 10s 18us/step - loss: 16.7951 - mean_squared_error: 862.1900\n67876/67876 [==============================] - 1s 22us/step\n"
    },
    {
     "data": {
      "text/plain": "14.663555800342216"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a smaller predictor network\n",
    "predictor = Sequential()\n",
    "predictor.add(Dense(8, activation=\"linear\", input_dim=X_train_fwd.shape[1]))\n",
    "predictor.add(Dropout(0.4))\n",
    "predictor.add(Dense(4, activation=\"tanh\"))\n",
    "predictor.add(Dropout(0.4))\n",
    "predictor.add(Dense(1, activation=\"linear\"))\n",
    "predictor.compile(\n",
    "    loss='mean_absolute_error', \n",
    "    optimizer=SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "\n",
    "predictor.fit(X_train_fwd, y_train, epochs=20, batch_size=256)\n",
    "\n",
    "forward = np.concatenate([classifier.predict(X_xval), X_xval[:,:len(X_NUM_COLS)]], axis=1)\n",
    "predictor.evaluate(forward, y_xval, batch_size=128)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "K MEANS\nCLASSIFIER\nEpoch 1/5\n542954/542954 [==============================] - 24s 44us/step - loss: 0.3726 - acc: 0.8286\nEpoch 2/5\n542954/542954 [==============================] - 20s 38us/step - loss: 0.3236 - acc: 0.8516\nEpoch 3/5\n542954/542954 [==============================] - 21s 38us/step - loss: 0.3112 - acc: 0.8614\nEpoch 4/5\n542954/542954 [==============================] - 21s 38us/step - loss: 0.3086 - acc: 0.8620\nEpoch 5/5\n542954/542954 [==============================] - 21s 38us/step - loss: 0.3068 - acc: 0.8626\n(542954, 10)\nPREDICTOR\nEpoch 1/20\n542954/542954 [==============================] - 12s 22us/step - loss: 18.1369 - mean_squared_error: 1000.1300\nEpoch 2/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5080 - mean_squared_error: 934.9683\nEpoch 3/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4990 - mean_squared_error: 933.7224\nEpoch 4/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5073 - mean_squared_error: 934.5382\nEpoch 5/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5065 - mean_squared_error: 935.1746\nEpoch 6/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5107 - mean_squared_error: 934.4038\nEpoch 7/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4947 - mean_squared_error: 933.2342\nEpoch 8/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5090 - mean_squared_error: 934.8422\nEpoch 9/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5193 - mean_squared_error: 935.7024\nEpoch 10/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5037 - mean_squared_error: 933.8080\nEpoch 11/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5194 - mean_squared_error: 935.0996\nEpoch 12/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5110 - mean_squared_error: 935.0848\nEpoch 13/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4954 - mean_squared_error: 934.1270\nEpoch 14/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4980 - mean_squared_error: 933.1416\nEpoch 15/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4942 - mean_squared_error: 933.1944\nEpoch 16/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4994 - mean_squared_error: 933.3182\nEpoch 17/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5003 - mean_squared_error: 935.1514\nEpoch 18/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.5010 - mean_squared_error: 933.0540\nEpoch 19/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4976 - mean_squared_error: 932.0431\nEpoch 20/20\n542954/542954 [==============================] - 9s 17us/step - loss: 17.4955 - mean_squared_error: 933.9694\n67876/67876 [==============================] - 2s 22us/step\n"
    },
    {
     "data": {
      "text/plain": "15.65815137514376"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next try again with only a few clusters (4)\n",
    "# transfer learning approach. Train a neural net to classify up to n clusters.\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.random import uniform, seed\n",
    "from keras.utils import np_utils\n",
    "\n",
    "n_clusters = 4\n",
    "# Best I could do at 6: 21 mae on training\n",
    "\n",
    "seed(10)\n",
    "print(\"K MEANS\")\n",
    "X_samp = X_train[uniform(size=X_train.shape[0]) < 0.1,:]\n",
    "kmeans = KMeans(n_clusters, n_jobs=-1)\n",
    "cluster_preds = kmeans.fit_predict(X_samp)\n",
    "X_classes = kmeans.predict(X_train)\n",
    "\n",
    "print(\"CLASSIFIER\")\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(32, activation=\"relu\", input_dim=X_train.shape[1]))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(n_clusters, activation='sigmoid'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(n_clusters, activation='sigmoid'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(n_clusters, activation='softmax'))\n",
    "\n",
    "classifier.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    #optimizer='adam',\n",
    "    optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "classifier.fit(\n",
    "    X_train, \n",
    "    np_utils.to_categorical(X_classes), \n",
    "    epochs=5, \n",
    "    batch_size=256)\n",
    "\n",
    "X_train_nums = X_train[:,:len(X_NUM_COLS)]\n",
    "X_train_fwd = np.concatenate([classifier.predict(X_train), X_train_nums], axis=1)  # (n, n_clusters + len(X_NUM_COLS))\n",
    "print(X_train_fwd.shape)\n",
    "\n",
    "print(\"PREDICTOR\")\n",
    "# Try a smaller predictor network\n",
    "predictor = Sequential()\n",
    "predictor.add(Dense(8, activation=\"linear\", input_dim=X_train_fwd.shape[1]))\n",
    "predictor.add(Dropout(0.4))\n",
    "predictor.add(Dense(4, activation=\"tanh\"))\n",
    "predictor.add(Dropout(0.4))\n",
    "predictor.add(Dense(1, activation=\"linear\"))\n",
    "predictor.compile(\n",
    "    loss='mean_absolute_error', \n",
    "    optimizer=SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "\n",
    "predictor.fit(X_train_fwd, y_train, epochs=20, batch_size=256)\n",
    "\n",
    "forward = np.concatenate([classifier.predict(X_xval), X_xval[:,:len(X_NUM_COLS)]], axis=1)\n",
    "predictor.evaluate(forward, y_xval, batch_size=128)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/10\n542954/542954 [==============================] - 18s 33us/step - loss: 19.5799 - mean_absolute_error: 19.5799 - mean_squared_error: 1061.7573\nEpoch 2/10\n542954/542954 [==============================] - 15s 27us/step - loss: 15.4098 - mean_absolute_error: 15.4098 - mean_squared_error: 699.5145\nEpoch 3/10\n542954/542954 [==============================] - 15s 27us/step - loss: 14.7907 - mean_absolute_error: 14.7907 - mean_squared_error: 664.1485\nEpoch 4/10\n542954/542954 [==============================] - 15s 27us/step - loss: 14.7151 - mean_absolute_error: 14.7151 - mean_squared_error: 588.5226\nEpoch 5/10\n542954/542954 [==============================] - 15s 27us/step - loss: 14.4890 - mean_absolute_error: 14.4890 - mean_squared_error: 599.8654\nEpoch 6/10\n542954/542954 [==============================] - 15s 27us/step - loss: 14.0169 - mean_absolute_error: 14.0169 - mean_squared_error: 594.1250\nEpoch 7/10\n542954/542954 [==============================] - 15s 27us/step - loss: 14.1448 - mean_absolute_error: 14.1448 - mean_squared_error: 629.4043\nEpoch 8/10\n542954/542954 [==============================] - 14s 27us/step - loss: 14.0957 - mean_absolute_error: 14.0957 - mean_squared_error: 597.9145\nEpoch 9/10\n542954/542954 [==============================] - 14s 27us/step - loss: 13.9819 - mean_absolute_error: 13.9819 - mean_squared_error: 587.4664\nEpoch 10/10\n542954/542954 [==============================] - 14s 26us/step - loss: 14.5732 - mean_absolute_error: 14.5732 - mean_squared_error: 678.2893\n67876/67876 [==============================] - 2s 32us/step\n13.026481550720122\n"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"linear\", input_dim=426))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=256)\n",
    "\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(xval_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/5\n542954/542954 [==============================] - 18s 34us/step - loss: 10.0502 - mean_absolute_error: 10.0502 - mean_squared_error: 342.7076\nEpoch 2/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.3352 - mean_absolute_error: 9.3352 - mean_squared_error: 282.5130\nEpoch 3/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.1425 - mean_absolute_error: 9.1425 - mean_squared_error: 267.0279\nEpoch 4/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.0709 - mean_absolute_error: 9.0709 - mean_squared_error: 261.0028\nEpoch 5/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.0289 - mean_absolute_error: 9.0289 - mean_squared_error: 260.1301\n67876/67876 [==============================] - 2s 34us/step\n7.448609103815916\n"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"sigmoid\", input_dim=426))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=256)\n",
    "\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(xval_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ACTIVATION: relu\nEpoch 1/5\n542954/542954 [==============================] - 18s 32us/step - loss: 10.3834 - mean_absolute_error: 10.3834 - mean_squared_error: 358.2582\nEpoch 2/5\n542954/542954 [==============================] - 15s 27us/step - loss: 9.8253 - mean_absolute_error: 9.8253 - mean_squared_error: 312.9068\nEpoch 3/5\n542954/542954 [==============================] - 14s 26us/step - loss: 9.6647 - mean_absolute_error: 9.6647 - mean_squared_error: 300.0488\nEpoch 4/5\n542954/542954 [==============================] - 15s 27us/step - loss: 9.6160 - mean_absolute_error: 9.6160 - mean_squared_error: 297.7739\nEpoch 5/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.5797 - mean_absolute_error: 9.5797 - mean_squared_error: 294.3923\n67876/67876 [==============================] - 2s 34us/step\nXVAL MAE: 8.229848937734253\nACTIVATION: tanh\nEpoch 1/5\n542954/542954 [==============================] - 18s 34us/step - loss: 11.8733 - mean_absolute_error: 11.8733 - mean_squared_error: 507.1493\nEpoch 2/5\n542954/542954 [==============================] - 15s 28us/step - loss: 10.9242 - mean_absolute_error: 10.9242 - mean_squared_error: 426.1671\nEpoch 3/5\n542954/542954 [==============================] - 15s 28us/step - loss: 10.8348 - mean_absolute_error: 10.8348 - mean_squared_error: 415.0650\nEpoch 4/5\n542954/542954 [==============================] - 16s 29us/step - loss: 10.7837 - mean_absolute_error: 10.7837 - mean_squared_error: 410.3641\nEpoch 5/5\n542954/542954 [==============================] - 16s 29us/step - loss: 10.7423 - mean_absolute_error: 10.7423 - mean_squared_error: 407.6684\n67876/67876 [==============================] - 2s 35us/step\nXVAL MAE: 8.778570294288862\nACTIVATION: linear\nEpoch 1/5\n542954/542954 [==============================] - 18s 33us/step - loss: 10.3936 - mean_absolute_error: 10.3936 - mean_squared_error: 402.4007\nEpoch 2/5\n542954/542954 [==============================] - 14s 27us/step - loss: 10.1397 - mean_absolute_error: 10.1397 - mean_squared_error: 385.6754\nEpoch 3/5\n542954/542954 [==============================] - 14s 27us/step - loss: 10.1374 - mean_absolute_error: 10.1374 - mean_squared_error: 383.6494\nEpoch 4/5\n542954/542954 [==============================] - 14s 27us/step - loss: 10.1463 - mean_absolute_error: 10.1463 - mean_squared_error: 384.7425\nEpoch 5/5\n542954/542954 [==============================] - 14s 27us/step - loss: 10.1455 - mean_absolute_error: 10.1455 - mean_squared_error: 385.3287\n67876/67876 [==============================] - 2s 33us/step\nXVAL MAE: 9.406058834946368\n"
    }
   ],
   "source": [
    "# Try other activation functions\n",
    "for act in ['relu', 'tanh', 'linear']:\n",
    "    print(f\"ACTIVATION: {act}\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation=act, input_dim=426))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=256)\n",
    "    xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "    print(f\"XVAL MAE: {xval_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1st layer size: 8\nEpoch 1/5\n542954/542954 [==============================] - 13s 24us/step - loss: 14.0998 - mean_absolute_error: 14.0998 - mean_squared_error: 613.1158\nEpoch 2/5\n542954/542954 [==============================] - 9s 17us/step - loss: 13.6424 - mean_absolute_error: 13.6424 - mean_squared_error: 562.9750\nEpoch 3/5\n542954/542954 [==============================] - 9s 17us/step - loss: 13.2836 - mean_absolute_error: 13.2836 - mean_squared_error: 529.4608\nEpoch 4/5\n542954/542954 [==============================] - 9s 17us/step - loss: 13.2173 - mean_absolute_error: 13.2173 - mean_squared_error: 524.4100\nEpoch 5/5\n542954/542954 [==============================] - 9s 17us/step - loss: 13.2125 - mean_absolute_error: 13.2125 - mean_squared_error: 525.3585\n67876/67876 [==============================] - 2s 32us/step\nXVAL MAE: 10.520857586001625\n1st layer size: 64\nEpoch 1/5\n542954/542954 [==============================] - 19s 35us/step - loss: 10.0374 - mean_absolute_error: 10.0374 - mean_squared_error: 342.1434\nEpoch 2/5\n542954/542954 [==============================] - 16s 29us/step - loss: 9.3315 - mean_absolute_error: 9.3315 - mean_squared_error: 283.6861\nEpoch 3/5\n542954/542954 [==============================] - 16s 29us/step - loss: 9.1314 - mean_absolute_error: 9.1314 - mean_squared_error: 267.9115\nEpoch 4/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.0574 - mean_absolute_error: 9.0574 - mean_squared_error: 261.1294\nEpoch 5/5\n542954/542954 [==============================] - 15s 28us/step - loss: 9.0191 - mean_absolute_error: 9.0191 - mean_squared_error: 257.7726\n67876/67876 [==============================] - 2s 36us/step\nXVAL MAE: 7.486555921061234\n1st layer size: 128\nEpoch 1/5\n542954/542954 [==============================] - 23s 43us/step - loss: 9.5560 - mean_absolute_error: 9.5560 - mean_squared_error: 322.6925\nEpoch 2/5\n542954/542954 [==============================] - 21s 38us/step - loss: 8.6567 - mean_absolute_error: 8.6567 - mean_squared_error: 255.1859\nEpoch 3/5\n542954/542954 [==============================] - 21s 38us/step - loss: 8.4251 - mean_absolute_error: 8.4251 - mean_squared_error: 235.6475\nEpoch 4/5\n542954/542954 [==============================] - 21s 38us/step - loss: 8.3157 - mean_absolute_error: 8.3157 - mean_squared_error: 229.1955\nEpoch 5/5\n542954/542954 [==============================] - 21s 38us/step - loss: 8.2667 - mean_absolute_error: 8.2667 - mean_squared_error: 225.8767\n67876/67876 [==============================] - 3s 42us/step\nXVAL MAE: 7.211624796315084\n1st layer size: 256\nEpoch 1/5\n542954/542954 [==============================] - 33s 61us/step - loss: 9.2873 - mean_absolute_error: 9.2873 - mean_squared_error: 314.9086\nEpoch 2/5\n542954/542954 [==============================] - 29s 54us/step - loss: 8.2595 - mean_absolute_error: 8.2595 - mean_squared_error: 241.7951\nEpoch 3/5\n542954/542954 [==============================] - 29s 54us/step - loss: 7.9865 - mean_absolute_error: 7.9865 - mean_squared_error: 221.6200\nEpoch 4/5\n542954/542954 [==============================] - 30s 55us/step - loss: 7.8548 - mean_absolute_error: 7.8548 - mean_squared_error: 212.8990\nEpoch 5/5\n542954/542954 [==============================] - 30s 56us/step - loss: 7.7722 - mean_absolute_error: 7.7722 - mean_squared_error: 208.6046\n67876/67876 [==============================] - 3s 43us/step\nXVAL MAE: 7.065202585183582\n"
    }
   ],
   "source": [
    "# Sigmoid is best. Experiment with different 1st layer sizes\n",
    "for sz in (8, 64, 128, 256):\n",
    "    print(f\"1st layer size: {sz}\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(sz, activation=\"sigmoid\", input_dim=426))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=256)\n",
    "    xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "    print(f\"XVAL MAE: {xval_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1st layer size: 200\nEpoch 1/6\n542954/542954 [==============================] - 31s 56us/step - loss: 9.3590 - mean_absolute_error: 9.3590 - mean_squared_error: 315.1599\nEpoch 2/6\n542954/542954 [==============================] - 27s 50us/step - loss: 8.3751 - mean_absolute_error: 8.3751 - mean_squared_error: 244.7735\nEpoch 3/6\n542954/542954 [==============================] - 28s 51us/step - loss: 8.1250 - mean_absolute_error: 8.1250 - mean_squared_error: 226.4966\nEpoch 4/6\n542954/542954 [==============================] - 26s 49us/step - loss: 7.9898 - mean_absolute_error: 7.9898 - mean_squared_error: 218.0753\nEpoch 5/6\n542954/542954 [==============================] - 26s 48us/step - loss: 7.9411 - mean_absolute_error: 7.9411 - mean_squared_error: 214.7887\nEpoch 6/6\n542954/542954 [==============================] - 26s 49us/step - loss: 7.8912 - mean_absolute_error: 7.8912 - mean_squared_error: 211.9460\n67876/67876 [==============================] - 3s 40us/step\nXVAL MAE: 7.077427285457586\n1st layer size: 512\nEpoch 1/6\n542954/542954 [==============================] - 43s 80us/step - loss: 9.2074 - mean_absolute_error: 9.2074 - mean_squared_error: 313.8950\nEpoch 2/6\n542954/542954 [==============================] - 39s 71us/step - loss: 8.1413 - mean_absolute_error: 8.1413 - mean_squared_error: 240.2806\nEpoch 3/6\n542954/542954 [==============================] - 38s 70us/step - loss: 7.8358 - mean_absolute_error: 7.8358 - mean_squared_error: 217.9059\nEpoch 4/6\n542954/542954 [==============================] - 38s 70us/step - loss: 7.6787 - mean_absolute_error: 7.6787 - mean_squared_error: 208.9733\nEpoch 5/6\n542954/542954 [==============================] - 38s 70us/step - loss: 7.5883 - mean_absolute_error: 7.5883 - mean_squared_error: 203.1083\nEpoch 6/6\n542954/542954 [==============================] - 38s 70us/step - loss: 7.5228 - mean_absolute_error: 7.5228 - mean_squared_error: 199.5662\n67876/67876 [==============================] - 3s 49us/step\nXVAL MAE: 7.004053317184714\n1st layer size: 600\nEpoch 1/6\n542954/542954 [==============================] - 45s 83us/step - loss: 9.2201 - mean_absolute_error: 9.2201 - mean_squared_error: 314.3077\nEpoch 2/6\n542954/542954 [==============================] - 42s 78us/step - loss: 8.1714 - mean_absolute_error: 8.1714 - mean_squared_error: 241.8893\nEpoch 3/6\n542954/542954 [==============================] - 43s 79us/step - loss: 7.8119 - mean_absolute_error: 7.8119 - mean_squared_error: 217.9291\nEpoch 4/6\n542954/542954 [==============================] - 42s 78us/step - loss: 7.6532 - mean_absolute_error: 7.6532 - mean_squared_error: 206.9046\nEpoch 5/6\n542954/542954 [==============================] - 42s 78us/step - loss: 7.5618 - mean_absolute_error: 7.5618 - mean_squared_error: 202.6375\nEpoch 6/6\n542954/542954 [==============================] - 43s 78us/step - loss: 7.4894 - mean_absolute_error: 7.4894 - mean_squared_error: 198.7304\n67876/67876 [==============================] - 3s 51us/step\nXVAL MAE: 6.979730711146821\n1st layer size: 1024\nEpoch 1/6\n542954/542954 [==============================] - 62s 114us/step - loss: 9.2907 - mean_absolute_error: 9.2907 - mean_squared_error: 317.5022\nEpoch 2/6\n542954/542954 [==============================] - 58s 108us/step - loss: 8.1583 - mean_absolute_error: 8.1583 - mean_squared_error: 243.3460\nEpoch 3/6\n542954/542954 [==============================] - 57s 106us/step - loss: 7.8064 - mean_absolute_error: 7.8064 - mean_squared_error: 218.4217\nEpoch 4/6\n542954/542954 [==============================] - 62s 114us/step - loss: 7.6440 - mean_absolute_error: 7.6440 - mean_squared_error: 208.7633\nEpoch 5/6\n542954/542954 [==============================] - 63s 115us/step - loss: 7.5402 - mean_absolute_error: 7.5402 - mean_squared_error: 203.2301\nEpoch 6/6\n542954/542954 [==============================] - 60s 111us/step - loss: 7.4680 - mean_absolute_error: 7.4680 - mean_squared_error: 199.1070\n67876/67876 [==============================] - 4s 57us/step\nXVAL MAE: 7.004750417366187\n"
    }
   ],
   "source": [
    "# ok, let's try a few options smaller and larger of 256 larger. With 1 more epoch for an additional boost.\n",
    "for sz in (200, 512, 600, 1024):\n",
    "    print(f\"1st layer size: {sz}\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(sz, activation=\"sigmoid\", input_dim=426))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    model.fit(X_train, y_train, epochs=6, batch_size=256)\n",
    "    xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "    print(f\"XVAL MAE: {xval_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/6\n423680/542954 [======================>.......] - ETA: 10s - loss: 16.8686 - mean_absolute_error: 16.8686 - mean_squared_error: 2435.3308"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-8caeca23bfcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mxval_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_xval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_xval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"XVAL MAE: {xval_mae}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# So 600 is the best in class so far. \n",
    "# What about adding another layer now that I think the combinations are being represented?\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=426))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation=\"linear\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=6, batch_size=256)\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/6\n542954/542954 [==============================] - 47s 87us/step - loss: 8.9467 - mean_absolute_error: 8.9467 - mean_squared_error: 305.1940\nEpoch 2/6\n542954/542954 [==============================] - 46s 85us/step - loss: 7.8276 - mean_absolute_error: 7.8276 - mean_squared_error: 226.5004\nEpoch 3/6\n542954/542954 [==============================] - 48s 88us/step - loss: 7.5184 - mean_absolute_error: 7.5184 - mean_squared_error: 204.6493\nEpoch 4/6\n542954/542954 [==============================] - 43s 80us/step - loss: 7.3761 - mean_absolute_error: 7.3761 - mean_squared_error: 196.7061\nEpoch 5/6\n542954/542954 [==============================] - 43s 80us/step - loss: 7.2721 - mean_absolute_error: 7.2721 - mean_squared_error: 191.5523\nEpoch 6/6\n542954/542954 [==============================] - 44s 82us/step - loss: 7.1995 - mean_absolute_error: 7.1995 - mean_squared_error: 186.9559\n67876/67876 [==============================] - 4s 55us/step\nXVAL MAE: 6.8486833875029935\n"
    }
   ],
   "source": [
    "# lol NOPE. What about less dropout?\n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=426))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=a0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=6, batch_size=256)\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/6\n542954/542954 [==============================] - 45s 83us/step - loss: 8.7379 - mean_absolute_error: 8.7379 - mean_squared_error: 298.2580\nEpoch 2/6\n542954/542954 [==============================] - 41s 75us/step - loss: 7.5712 - mean_absolute_error: 7.5712 - mean_squared_error: 215.7863\nEpoch 3/6\n542954/542954 [==============================] - 41s 76us/step - loss: 7.2834 - mean_absolute_error: 7.2834 - mean_squared_error: 196.5177\nEpoch 4/6\n542954/542954 [==============================] - 42s 78us/step - loss: 7.1396 - mean_absolute_error: 7.1396 - mean_squared_error: 187.9118\nEpoch 5/6\n542954/542954 [==============================] - 42s 77us/step - loss: 7.0345 - mean_absolute_error: 7.0345 - mean_squared_error: 181.5814\nEpoch 6/6\n542954/542954 [==============================] - 42s 77us/step - loss: 6.9471 - mean_absolute_error: 6.9471 - mean_squared_error: 176.8085\n67876/67876 [==============================] - 4s 56us/step\nXVAL MAE: 6.733853124014033\n"
    }
   ],
   "source": [
    "# lol NOPE. What about less dropout?\n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=426))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=6, batch_size=256)\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/8\n542954/542954 [==============================] - 46s 86us/step - loss: 8.3457 - mean_absolute_error: 8.3457 - mean_squared_error: 263.4149\nEpoch 2/8\n542954/542954 [==============================] - 44s 81us/step - loss: 7.3332 - mean_absolute_error: 7.3332 - mean_squared_error: 196.4161\nEpoch 3/8\n542954/542954 [==============================] - 44s 81us/step - loss: 7.1090 - mean_absolute_error: 7.1090 - mean_squared_error: 183.8373\nEpoch 4/8\n542954/542954 [==============================] - 44s 80us/step - loss: 6.9679 - mean_absolute_error: 6.9679 - mean_squared_error: 175.7016\nEpoch 5/8\n542954/542954 [==============================] - 42s 77us/step - loss: 6.8636 - mean_absolute_error: 6.8636 - mean_squared_error: 170.0832\nEpoch 6/8\n542954/542954 [==============================] - 42s 77us/step - loss: 6.7946 - mean_absolute_error: 6.7946 - mean_squared_error: 166.8979\nEpoch 7/8\n542954/542954 [==============================] - 42s 77us/step - loss: 6.7455 - mean_absolute_error: 6.7455 - mean_squared_error: 163.8662\nEpoch 8/8\n542954/542954 [==============================] - 42s 77us/step - loss: 6.7011 - mean_absolute_error: 6.7011 - mean_squared_error: 162.2723\n67876/67876 [==============================] - 4s 55us/step\nXVAL MAE: 6.526257157178217\n"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=426))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=8, batch_size=256)\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/2\n542954/542954 [==============================] - 43s 79us/step - loss: 6.6655 - mean_absolute_error: 6.6655 - mean_squared_error: 160.6850\nEpoch 2/2\n542954/542954 [==============================] - 43s 80us/step - loss: 6.6320 - mean_absolute_error: 6.6320 - mean_squared_error: 158.8025\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a72c22a90>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/3\n542954/542954 [==============================] - 43s 79us/step - loss: 6.6067 - mean_absolute_error: 6.6067 - mean_squared_error: 158.1593\nEpoch 2/3\n542954/542954 [==============================] - 42s 78us/step - loss: 6.5896 - mean_absolute_error: 6.5896 - mean_squared_error: 157.3695\nEpoch 3/3\n542954/542954 [==============================] - 43s 79us/step - loss: 6.5586 - mean_absolute_error: 6.5586 - mean_squared_error: 155.9653\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a72a50080>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/2\n542954/542954 [==============================] - 43s 79us/step - loss: 6.5446 - mean_absolute_error: 6.5446 - mean_squared_error: 155.5750\nEpoch 2/2\n542954/542954 [==============================] - 43s 80us/step - loss: 6.5193 - mean_absolute_error: 6.5193 - mean_squared_error: 154.3072\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a72a50048>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "67876/67876 [==============================] - 2s 34us/step\nXVAL MAE: 6.399070236831684\n"
    }
   ],
   "source": [
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/4\n542954/542954 [==============================] - 43s 79us/step - loss: 6.5035 - mean_absolute_error: 6.5035 - mean_squared_error: 153.8057\nEpoch 2/4\n542954/542954 [==============================] - 43s 80us/step - loss: 6.4824 - mean_absolute_error: 6.4824 - mean_squared_error: 153.1254\nEpoch 3/4\n542954/542954 [==============================] - 45s 82us/step - loss: 6.4722 - mean_absolute_error: 6.4722 - mean_squared_error: 152.6193\nEpoch 4/4\n542954/542954 [==============================] - 45s 83us/step - loss: 6.4540 - mean_absolute_error: 6.4540 - mean_squared_error: 151.9311\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a47d61be0>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "67876/67876 [==============================] - 2s 33us/step\nXVAL MAE: 6.331358876153304\nEpoch 1/4\n542954/542954 [==============================] - 43s 78us/step - loss: 6.4416 - mean_absolute_error: 6.4416 - mean_squared_error: 151.2298\nEpoch 2/4\n542954/542954 [==============================] - 44s 82us/step - loss: 6.4304 - mean_absolute_error: 6.4304 - mean_squared_error: 150.9122\nEpoch 3/4\n542954/542954 [==============================] - 45s 82us/step - loss: 6.4164 - mean_absolute_error: 6.4164 - mean_squared_error: 150.0803\nEpoch 4/4\n542954/542954 [==============================] - 43s 79us/step - loss: 6.4023 - mean_absolute_error: 6.4023 - mean_squared_error: 149.4390\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a47d79b00>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "67876/67876 [==============================] - 2s 32us/step\nXVAL MAE: 6.4226108718982\n"
    }
   ],
   "source": [
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/15\n542954/542954 [==============================] - 45s 82us/step - loss: 8.3531 - mean_absolute_error: 8.3531 - mean_squared_error: 264.6620\nEpoch 2/15\n542954/542954 [==============================] - 42s 77us/step - loss: 7.3503 - mean_absolute_error: 7.3503 - mean_squared_error: 197.5880\nEpoch 3/15\n542954/542954 [==============================] - 41s 76us/step - loss: 7.1092 - mean_absolute_error: 7.1092 - mean_squared_error: 183.6092\nEpoch 4/15\n542954/542954 [==============================] - 41s 76us/step - loss: 6.9605 - mean_absolute_error: 6.9605 - mean_squared_error: 175.3608\nEpoch 5/15\n542954/542954 [==============================] - 41s 76us/step - loss: 6.8583 - mean_absolute_error: 6.8583 - mean_squared_error: 169.7260\nEpoch 6/15\n542954/542954 [==============================] - 41s 76us/step - loss: 6.7917 - mean_absolute_error: 6.7917 - mean_squared_error: 166.0013\nEpoch 7/15\n542954/542954 [==============================] - 42s 78us/step - loss: 6.7328 - mean_absolute_error: 6.7328 - mean_squared_error: 163.3722\nEpoch 8/15\n542954/542954 [==============================] - 42s 78us/step - loss: 6.7018 - mean_absolute_error: 6.7018 - mean_squared_error: 161.7809\nEpoch 9/15\n542954/542954 [==============================] - 43s 78us/step - loss: 6.6595 - mean_absolute_error: 6.6595 - mean_squared_error: 160.1243\nEpoch 10/15\n542954/542954 [==============================] - 42s 78us/step - loss: 6.6351 - mean_absolute_error: 6.6351 - mean_squared_error: 158.9085\nEpoch 11/15\n542954/542954 [==============================] - 43s 78us/step - loss: 6.6138 - mean_absolute_error: 6.6138 - mean_squared_error: 158.1558\nEpoch 12/15\n542954/542954 [==============================] - 42s 78us/step - loss: 6.5893 - mean_absolute_error: 6.5893 - mean_squared_error: 156.8610\nEpoch 13/15\n542954/542954 [==============================] - 43s 79us/step - loss: 6.5686 - mean_absolute_error: 6.5686 - mean_squared_error: 156.2209\nEpoch 14/15\n542954/542954 [==============================] - 43s 78us/step - loss: 6.5481 - mean_absolute_error: 6.5481 - mean_squared_error: 155.0466\nEpoch 15/15\n542954/542954 [==============================] - 42s 77us/step - loss: 6.5316 - mean_absolute_error: 6.5316 - mean_squared_error: 154.4265\n67876/67876 [==============================] - 4s 56us/step\nXVAL MAE: 6.391801264650083\n"
    }
   ],
   "source": [
    "#best fit\n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=426))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=256)\n",
    "xval_mae = model.evaluate(X_xval, y_xval, batch_size=128)[0]\n",
    "print(f\"XVAL MAE: {xval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_xval)\n",
    "with open(\"../predictions/nn_15min_xval.txt\", 'wt') as out:\n",
    "    for pred in preds:\n",
    "        out.write(str(pred)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/15\n424373/424373 [==============================] - 32s 76us/step - loss: 10.6505 - mean_absolute_error: 10.6505 - mean_squared_error: 531.3505\nEpoch 2/15\n424373/424373 [==============================] - 28s 67us/step - loss: 9.1163 - mean_absolute_error: 9.1163 - mean_squared_error: 342.5813\nEpoch 3/15\n424373/424373 [==============================] - 29s 68us/step - loss: 8.7286 - mean_absolute_error: 8.7286 - mean_squared_error: 303.7920\nEpoch 4/15\n424373/424373 [==============================] - 29s 68us/step - loss: 8.4910 - mean_absolute_error: 8.4910 - mean_squared_error: 282.5649\nEpoch 5/15\n424373/424373 [==============================] - 28s 67us/step - loss: 8.3449 - mean_absolute_error: 8.3449 - mean_squared_error: 269.7534\nEpoch 6/15\n424373/424373 [==============================] - 28s 67us/step - loss: 8.2425 - mean_absolute_error: 8.2425 - mean_squared_error: 262.1305\nEpoch 7/15\n424373/424373 [==============================] - 28s 66us/step - loss: 8.1556 - mean_absolute_error: 8.1556 - mean_squared_error: 255.1390\nEpoch 8/15\n424373/424373 [==============================] - 28s 67us/step - loss: 8.1034 - mean_absolute_error: 8.1034 - mean_squared_error: 252.1288\nEpoch 9/15\n424373/424373 [==============================] - 29s 67us/step - loss: 8.0468 - mean_absolute_error: 8.0468 - mean_squared_error: 248.7945\nEpoch 10/15\n424373/424373 [==============================] - 28s 66us/step - loss: 8.0130 - mean_absolute_error: 8.0130 - mean_squared_error: 246.2514\nEpoch 11/15\n424373/424373 [==============================] - 28s 67us/step - loss: 7.9779 - mean_absolute_error: 7.9779 - mean_squared_error: 244.7148\nEpoch 12/15\n424373/424373 [==============================] - 29s 67us/step - loss: 7.9548 - mean_absolute_error: 7.9548 - mean_squared_error: 242.8405\nEpoch 13/15\n424373/424373 [==============================] - 29s 67us/step - loss: 7.9260 - mean_absolute_error: 7.9260 - mean_squared_error: 241.1349\nEpoch 14/15\n424373/424373 [==============================] - 29s 68us/step - loss: 7.8901 - mean_absolute_error: 7.8901 - mean_squared_error: 240.3044\nEpoch 15/15\n424373/424373 [==============================] - 29s 68us/step - loss: 7.8733 - mean_absolute_error: 7.8733 - mean_squared_error: 238.7743\n53071/53071 [==============================] - 3s 60us/step\nXVAL MAE: 7.789570094983333\n"
    }
   ],
   "source": [
    "# Ok. Produce predictions from the best model so far, also fit and predict on :\n",
    "# combined, 30 min (also re-scale model)\n",
    "train, xval = pd.read_csv('../combined_data/30min/train.tsv.gz', sep='\\t'), pd.read_csv(\"../combined_data/30min/xval.tsv.gz\", sep='\\t')\n",
    "\n",
    "X_NUM_COLS = [\n",
    "    'orca_total', 'frac_disabled', 'frac_youth', 'frac_senior', 'frac_li', 'frac_uw'\n",
    "]\n",
    "X_CAT_COLS = ['is_ns', 'is_rapid', 'is_weekend', 'trip_start_hr_30', 'rte', 'dir', 'day_of_week', 'region', 'start', 'end', 'summer']\n",
    "\n",
    "\n",
    "label_encoders = {col: LabelEncoder() for col in X_CAT_COLS}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.concatenate((\n",
    "    scaler.fit_transform(train[X_NUM_COLS]),\n",
    "    one_hot_encoder.fit_transform(\n",
    "        np.stack([label_encoders[col].fit_transform(train[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "X_xval = np.concatenate((\n",
    "    scaler.transform(xval[X_NUM_COLS]),\n",
    "    one_hot_encoder.transform(\n",
    "        np.stack([label_encoders[col].transform(xval[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "\n",
    "y_train = train['ons']\n",
    "y_xval = xval['ons']\n",
    "\n",
    "column_labels = list()\n",
    "column_labels.extend(X_NUM_COLS)\n",
    "for cat in X_CAT_COLS:\n",
    "    for clazz in label_encoders[cat].classes_:\n",
    "        column_labels.append(f'{cat}: {clazz}')\n",
    "\n",
    "#best fit\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"sigmoid\", input_dim=378))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=15, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_xval)\n",
    "with open(\"../predictions/nn_30min_xval.txt\", 'wt') as out:\n",
    "    for pred in preds:\n",
    "        out.write(str(pred)+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 225708 samples, validate on 28498 samples\nEpoch 1/5\n225708/225708 [==============================] - 23s 104us/step - loss: 8.3027 - mean_absolute_error: 8.3027 - mean_squared_error: 304.4028 - val_loss: 7.0636 - val_mean_absolute_error: 7.0636 - val_mean_squared_error: 204.8016\nEpoch 2/5\n225708/225708 [==============================] - 18s 78us/step - loss: 6.9415 - mean_absolute_error: 6.9415 - mean_squared_error: 202.4186 - val_loss: 6.6721 - val_mean_absolute_error: 6.6721 - val_mean_squared_error: 192.4184\nEpoch 3/5\n225708/225708 [==============================] - 18s 80us/step - loss: 6.7348 - mean_absolute_error: 6.7348 - mean_squared_error: 187.2427 - val_loss: 6.5133 - val_mean_absolute_error: 6.5133 - val_mean_squared_error: 177.3020\nEpoch 4/5\n225708/225708 [==============================] - 18s 78us/step - loss: 6.5926 - mean_absolute_error: 6.5926 - mean_squared_error: 176.4678 - val_loss: 6.4085 - val_mean_absolute_error: 6.4085 - val_mean_squared_error: 163.3112\nEpoch 5/5\n225708/225708 [==============================] - 18s 81us/step - loss: 6.4796 - mean_absolute_error: 6.4796 - mean_squared_error: 168.4372 - val_loss: 6.3125 - val_mean_absolute_error: 6.3125 - val_mean_squared_error: 161.6054\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a4690d7b8>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# winter only, 15 min\n",
    "train, xval = pd.read_csv('../winter_data/aggregates/15min/train.tsv.gz', sep='\\t'), pd.read_csv(\"../winter_data/aggregates/15min/xval.tsv.gz\", sep='\\t')\n",
    "\n",
    "X_NUM_COLS = [\n",
    "    'orca_total', 'frac_disabled', 'frac_youth', 'frac_senior', 'frac_li', 'frac_uw'\n",
    "]\n",
    "X_CAT_COLS = ['is_ns', 'is_rapid', 'is_weekend', 'trip_start_hr_15', 'rte', 'dir', 'day_of_week', 'region', 'start', 'end', 'summer']\n",
    "\n",
    "\n",
    "label_encoders = {col: LabelEncoder() for col in X_CAT_COLS}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.concatenate((\n",
    "    scaler.fit_transform(train[X_NUM_COLS]),\n",
    "    one_hot_encoder.fit_transform(\n",
    "        np.stack([label_encoders[col].fit_transform(train[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "X_xval = np.concatenate((\n",
    "    scaler.transform(xval[X_NUM_COLS]),\n",
    "    one_hot_encoder.transform(\n",
    "        np.stack([label_encoders[col].transform(xval[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "\n",
    "y_train = train['ons']\n",
    "y_xval = xval['ons']\n",
    "\n",
    "column_labels = list()\n",
    "column_labels.extend(X_NUM_COLS)\n",
    "for cat in X_CAT_COLS:\n",
    "    for clazz in label_encoders[cat].classes_:\n",
    "        column_labels.append(f'{cat}: {clazz}')\n",
    "\n",
    "#less aggressive fit for more homogenous data\n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=425))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=5, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 225708 samples, validate on 28498 samples\nEpoch 1/2\n225708/225708 [==============================] - 18s 81us/step - loss: 6.3970 - mean_absolute_error: 6.3970 - mean_squared_error: 161.3225 - val_loss: 6.2226 - val_mean_absolute_error: 6.2226 - val_mean_squared_error: 160.3527\nEpoch 2/2\n225708/225708 [==============================] - 18s 78us/step - loss: 6.3398 - mean_absolute_error: 6.3398 - mean_squared_error: 157.8516 - val_loss: 6.2047 - val_mean_absolute_error: 6.2047 - val_mean_squared_error: 159.7342\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a45f9d630>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 225708 samples, validate on 28498 samples\nEpoch 1/2\n225708/225708 [==============================] - 19s 83us/step - loss: 6.2932 - mean_absolute_error: 6.2932 - mean_squared_error: 154.7478 - val_loss: 6.1522 - val_mean_absolute_error: 6.1522 - val_mean_squared_error: 153.4196\nEpoch 2/2\n225708/225708 [==============================] - 19s 86us/step - loss: 6.2447 - mean_absolute_error: 6.2447 - mean_squared_error: 151.8267 - val_loss: 6.1855 - val_mean_absolute_error: 6.1855 - val_mean_squared_error: 146.3405\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a460cc470>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_xval)\n",
    "with open(\"../predictions/nn_15min_winter_xval.txt\", 'wt') as out:\n",
    "    for pred in preds:\n",
    "        out.write(str(pred)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 175074 samples, validate on 22386 samples\nEpoch 1/15\n175074/175074 [==============================] - 18s 100us/step - loss: 11.1047 - mean_absolute_error: 11.1047 - mean_squared_error: 700.7879 - val_loss: 9.0730 - val_mean_absolute_error: 9.0730 - val_mean_squared_error: 464.1272\nEpoch 2/15\n175074/175074 [==============================] - 12s 70us/step - loss: 8.6619 - mean_absolute_error: 8.6619 - mean_squared_error: 418.5517 - val_loss: 8.4057 - val_mean_absolute_error: 8.4057 - val_mean_squared_error: 390.2757\nEpoch 3/15\n175074/175074 [==============================] - 13s 72us/step - loss: 8.3264 - mean_absolute_error: 8.3264 - mean_squared_error: 371.3515 - val_loss: 8.0818 - val_mean_absolute_error: 8.0818 - val_mean_squared_error: 357.5992\nEpoch 4/15\n175074/175074 [==============================] - 13s 76us/step - loss: 8.0816 - mean_absolute_error: 8.0816 - mean_squared_error: 334.2666 - val_loss: 7.8811 - val_mean_absolute_error: 7.8811 - val_mean_squared_error: 324.4874\nEpoch 5/15\n175074/175074 [==============================] - 14s 79us/step - loss: 7.8969 - mean_absolute_error: 7.8969 - mean_squared_error: 307.7449 - val_loss: 7.6351 - val_mean_absolute_error: 7.6351 - val_mean_squared_error: 300.3202\nEpoch 6/15\n175074/175074 [==============================] - 13s 75us/step - loss: 7.7489 - mean_absolute_error: 7.7489 - mean_squared_error: 288.3756 - val_loss: 7.5842 - val_mean_absolute_error: 7.5842 - val_mean_squared_error: 274.3473\nEpoch 7/15\n175074/175074 [==============================] - 13s 75us/step - loss: 7.6243 - mean_absolute_error: 7.6243 - mean_squared_error: 272.3846 - val_loss: 7.4337 - val_mean_absolute_error: 7.4337 - val_mean_squared_error: 254.8881\nEpoch 8/15\n175074/175074 [==============================] - 13s 75us/step - loss: 7.5304 - mean_absolute_error: 7.5304 - mean_squared_error: 259.7480 - val_loss: 7.3019 - val_mean_absolute_error: 7.3019 - val_mean_squared_error: 250.1831\nEpoch 9/15\n175074/175074 [==============================] - 13s 75us/step - loss: 7.4451 - mean_absolute_error: 7.4451 - mean_squared_error: 251.6876 - val_loss: 7.2871 - val_mean_absolute_error: 7.2871 - val_mean_squared_error: 235.9031\nEpoch 10/15\n175074/175074 [==============================] - 13s 74us/step - loss: 7.3691 - mean_absolute_error: 7.3691 - mean_squared_error: 245.1782 - val_loss: 7.2946 - val_mean_absolute_error: 7.2946 - val_mean_squared_error: 232.5787\nEpoch 11/15\n 64768/175074 [==========>...................] - ETA: 7s - loss: 7.3034 - mean_absolute_error: 7.3034 - mean_squared_error: 236.8412"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7d112e4a8a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_xval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_xval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# winter only, 30 min\n",
    "train, xval = pd.read_csv('../winter_data/aggregates/30min/train.tsv.gz', sep='\\t'), pd.read_csv(\"../winter_data/aggregates/30min/xval.tsv.gz\", sep='\\t')\n",
    "\n",
    "X_NUM_COLS = [\n",
    "    'orca_total', 'frac_disabled', 'frac_youth', 'frac_senior', 'frac_li', 'frac_uw'\n",
    "]\n",
    "X_CAT_COLS = ['is_ns', 'is_rapid', 'is_weekend', 'trip_start_hr_30', 'rte', 'dir', 'day_of_week', 'region', 'start', 'end', 'summer']\n",
    "\n",
    "\n",
    "label_encoders = {col: LabelEncoder() for col in X_CAT_COLS}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.concatenate((\n",
    "    scaler.fit_transform(train[X_NUM_COLS]),\n",
    "    one_hot_encoder.fit_transform(\n",
    "        np.stack([label_encoders[col].fit_transform(train[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "X_xval = np.concatenate((\n",
    "    scaler.transform(xval[X_NUM_COLS]),\n",
    "    one_hot_encoder.transform(\n",
    "        np.stack([label_encoders[col].transform(xval[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "\n",
    "y_train = train['ons']\n",
    "y_xval = xval['ons']\n",
    "\n",
    "column_labels = list()\n",
    "column_labels.extend(X_NUM_COLS)\n",
    "for cat in X_CAT_COLS:\n",
    "    for clazz in label_encoders[cat].classes_:\n",
    "        column_labels.append(f'{cat}: {clazz}')\n",
    "\n",
    "#best fit\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"sigmoid\", input_dim=377))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=15, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_xval)\n",
    "with open(\"../predictions/nn_30min_winter_xval.txt\", 'wt') as out:\n",
    "    for pred in preds:\n",
    "        out.write(str(pred)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 316444 samples, validate on 39948 samples\nEpoch 1/10\n316444/316444 [==============================] - 30s 96us/step - loss: 9.8631 - mean_absolute_error: 9.8631 - mean_squared_error: 358.1413 - val_loss: 8.7822 - val_mean_absolute_error: 8.7822 - val_mean_squared_error: 275.1887\nEpoch 2/10\n316444/316444 [==============================] - 26s 81us/step - loss: 8.4541 - mean_absolute_error: 8.4541 - mean_squared_error: 261.1516 - val_loss: 8.0937 - val_mean_absolute_error: 8.0937 - val_mean_squared_error: 240.4972\nEpoch 3/10\n316444/316444 [==============================] - 27s 84us/step - loss: 8.0472 - mean_absolute_error: 8.0472 - mean_squared_error: 235.4908 - val_loss: 7.8639 - val_mean_absolute_error: 7.8639 - val_mean_squared_error: 224.0024\nEpoch 4/10\n316444/316444 [==============================] - 26s 82us/step - loss: 7.8565 - mean_absolute_error: 7.8565 - mean_squared_error: 223.1352 - val_loss: 7.7216 - val_mean_absolute_error: 7.7216 - val_mean_squared_error: 207.8714\nEpoch 5/10\n316444/316444 [==============================] - 26s 82us/step - loss: 7.7227 - mean_absolute_error: 7.7227 - mean_squared_error: 215.0229 - val_loss: 7.6874 - val_mean_absolute_error: 7.6874 - val_mean_squared_error: 217.2262\nEpoch 6/10\n316444/316444 [==============================] - 26s 82us/step - loss: 7.6238 - mean_absolute_error: 7.6238 - mean_squared_error: 209.3082 - val_loss: 7.6772 - val_mean_absolute_error: 7.6772 - val_mean_squared_error: 196.2773\nEpoch 7/10\n316444/316444 [==============================] - 26s 82us/step - loss: 7.5435 - mean_absolute_error: 7.5435 - mean_squared_error: 204.2919 - val_loss: 7.4250 - val_mean_absolute_error: 7.4250 - val_mean_squared_error: 192.8989\nEpoch 8/10\n316444/316444 [==============================] - 26s 82us/step - loss: 7.4695 - mean_absolute_error: 7.4695 - mean_squared_error: 199.7716 - val_loss: 7.3738 - val_mean_absolute_error: 7.3738 - val_mean_squared_error: 188.0856\nEpoch 9/10\n316444/316444 [==============================] - 26s 83us/step - loss: 7.4051 - mean_absolute_error: 7.4051 - mean_squared_error: 196.5190 - val_loss: 7.4148 - val_mean_absolute_error: 7.4148 - val_mean_squared_error: 183.4224\nEpoch 10/10\n 40704/316444 [==>...........................] - ETA: 23s - loss: 7.3036 - mean_absolute_error: 7.3036 - mean_squared_error: 187.1380"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-a6c614e07ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_xval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_xval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# summer only, 15 min\n",
    "train, xval = pd.read_csv('../summer_data/aggregates/15min/train.tsv.gz', sep='\\t'), pd.read_csv(\"../summer_data/aggregates/15min/xval.tsv.gz\", sep='\\t')\n",
    "\n",
    "X_NUM_COLS = [\n",
    "    'orca_total', 'frac_disabled', 'frac_youth', 'frac_senior', 'frac_li', 'frac_uw'\n",
    "]\n",
    "X_CAT_COLS = ['is_ns', 'is_rapid', 'is_weekend', 'trip_start_hr_15', 'rte', 'dir', 'day_of_week', 'region', 'start', 'end', 'summer']\n",
    "\n",
    "\n",
    "label_encoders = {col: LabelEncoder() for col in X_CAT_COLS}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.concatenate((\n",
    "    scaler.fit_transform(train[X_NUM_COLS]),\n",
    "    one_hot_encoder.fit_transform(\n",
    "        np.stack([label_encoders[col].fit_transform(train[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "X_xval = np.concatenate((\n",
    "    scaler.transform(xval[X_NUM_COLS]),\n",
    "    one_hot_encoder.transform(\n",
    "        np.stack([label_encoders[col].transform(xval[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "\n",
    "y_train = train['ons']\n",
    "y_xval = xval['ons']\n",
    "\n",
    "column_labels = list()\n",
    "column_labels.extend(X_NUM_COLS)\n",
    "for cat in X_CAT_COLS:\n",
    "    for clazz in label_encoders[cat].classes_:\n",
    "        column_labels.append(f'{cat}: {clazz}')\n",
    "\n",
    "#less aggressive fit for more homogenous data\n",
    "model = Sequential()\n",
    "model.add(Dense(600, activation=\"sigmoid\", input_dim=416))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=10, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_xval)\n",
    "with open(\"../predictions/nn_15min_summer_xval.txt\", 'wt') as out:\n",
    "    for pred in preds:\n",
    "        out.write(str(pred)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 248579 samples, validate on 31495 samples\nEpoch 1/5\n248579/248579 [==============================] - 23s 94us/step - loss: 12.8144 - mean_absolute_error: 12.8144 - mean_squared_error: 737.2911 - val_loss: 15.8556 - val_mean_absolute_error: 15.8556 - val_mean_squared_error: 913.4162\nEpoch 2/5\n248579/248579 [==============================] - 18s 71us/step - loss: 10.8740 - mean_absolute_error: 10.8740 - mean_squared_error: 508.2829 - val_loss: 12.7028 - val_mean_absolute_error: 12.7028 - val_mean_squared_error: 452.7576\nEpoch 3/5\n248579/248579 [==============================] - 18s 72us/step - loss: 10.2558 - mean_absolute_error: 10.2558 - mean_squared_error: 431.8868 - val_loss: 11.3673 - val_mean_absolute_error: 11.3673 - val_mean_squared_error: 471.2871\nEpoch 4/5\n248579/248579 [==============================] - 18s 74us/step - loss: 9.8896 - mean_absolute_error: 9.8896 - mean_squared_error: 389.9734 - val_loss: 10.8307 - val_mean_absolute_error: 10.8307 - val_mean_squared_error: 412.2006\nEpoch 5/5\n248579/248579 [==============================] - 18s 73us/step - loss: 9.6351 - mean_absolute_error: 9.6351 - mean_squared_error: 361.8617 - val_loss: 9.9822 - val_mean_absolute_error: 9.9822 - val_mean_squared_error: 353.3602\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1a525290f0>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summer only, 30 min\n",
    "train, xval = pd.read_csv('../summer_data/aggregates/30min/train.tsv.gz', sep='\\t'), pd.read_csv(\"../summer_data/aggregates/30min/xval.tsv.gz\", sep='\\t')\n",
    "\n",
    "X_NUM_COLS = [\n",
    "    'orca_total', 'frac_disabled', 'frac_youth', 'frac_senior', 'frac_li', 'frac_uw'\n",
    "]\n",
    "X_CAT_COLS = ['is_ns', 'is_rapid', 'is_weekend', 'trip_start_hr_30', 'rte', 'dir', 'day_of_week', 'region', 'start', 'end', 'summer']\n",
    "\n",
    "\n",
    "label_encoders = {col: LabelEncoder() for col in X_CAT_COLS}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.concatenate((\n",
    "    scaler.fit_transform(train[X_NUM_COLS]),\n",
    "    one_hot_encoder.fit_transform(\n",
    "        np.stack([label_encoders[col].fit_transform(train[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "X_xval = np.concatenate((\n",
    "    scaler.transform(xval[X_NUM_COLS]),\n",
    "    one_hot_encoder.transform(\n",
    "        np.stack([label_encoders[col].transform(xval[col]) for col in X_CAT_COLS]).T\n",
    "    ).todense()\n",
    "), axis=1)\n",
    "\n",
    "y_train = train['ons']\n",
    "y_xval = xval['ons']\n",
    "\n",
    "column_labels = list()\n",
    "column_labels.extend(X_NUM_COLS)\n",
    "for cat in X_CAT_COLS:\n",
    "    for clazz in label_encoders[cat].classes_:\n",
    "        column_labels.append(f'{cat}: {clazz}')\n",
    "\n",
    "#best fit\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"sigmoid\", input_dim=368))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_xval)\n",
    "with open(\"../predictions/nn_30min_summer_xval.txt\", 'wt') as out:\n",
    "    for pred in preds:\n",
    "        out.write(str(pred)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}